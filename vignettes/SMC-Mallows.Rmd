---
title: "Online Learning: Sequential Monte Carlo for the Bayesian Mallows model"
output: 
  rmarkdown::html_vignette:
    fig_width: 6
    fig_height: 4
bibliography: ../inst/REFERENCES.bib
link-citations: yes
vignette: >
  %\VignetteIndexEntry{Online Learning: Sequential Monte Carlo for the Bayesian Mallows model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---




```r
library(BayesMallows)
library(ggplot2)
set.seed(123)
```


This vignette describes sequential Monte Carlo (SMC) algorithms to provide updated approximations to the posterior distribution of a single Mallows model. We consider scenarios where we receive sequential information in the form of complete rankings, partial rankings and updated rankings from existing individuals who have previously provided a (partial) ranking. This vignette focuses on the code. For an in-depth treatment of the implemented methodology, see @steinSequentialInferenceMallows2023 which is available [here](https://eprints.lancs.ac.uk/id/eprint/195759/). 


## Online learning with new users arriving

We use the `sushi_rankings` dataset to illustrate the methodology [@kamishima2003nantonac]. This dataset contains 5000 complete rankings for 10 sushi dishes.


```r
head(sushi_rankings)
#>      shrimp sea eel tuna squid sea urchin salmon roe egg fatty tuna tuna roll cucumber roll
#> [1,]      2       8   10     3          4          1   5          9         7             6
#> [2,]      1       8    6     4         10          9   3          5         7             2
#> [3,]      2       8    3     4          6          7  10          1         5             9
#> [4,]      4       7    5     6          1          2   8          3         9            10
#> [5,]      4      10    7     5          9          3   2          8         1             6
#> [6,]      4       6    2    10          7          5   1          9         8             3
```

The SMC methodology is designed for the case where date arrive in batches. Assume that we initially have only 300 observed rankings, in `data_batch1`:


```r
data_batch1 <- sushi_rankings[1:300, ]
```

We estimate a model on these data using `compute_mallows()`, which runs a full Metropolis-Hastings algorithm.


```r
model1 <- compute_mallows(data = setup_rank_data(data_batch1))
```

We assess convergence, and find that 300 is an appropriate burnin value.


```r
assess_convergence(model1)
```

<div class="figure">
<img src="convergence_smc_full-1.png" alt="Trace plot for SMC model." height="5cm" />
<p class="caption">Trace plot for SMC model.</p>
</div>



```r
model1$burnin <- 300
```

Having saved this model, assume we receive another batch of preferences at a later timepoint, with an additional 300 rankings.


```r
data_batch2 <- sushi_rankings[301:600, ]
```

We can now update the initial model, without rerunning the full Metropolis-Hastings algorithm, by calling `update_mallows()`. This function uses the sequential Monte Carlo algorithm of @steinSequentialInferenceMallows2023, and extracts a thinned sample of size `n_particles` from `model1` as initial values.


```r
model2 <- update_mallows(model = model1, 
                         new_data = setup_rank_data(data_batch2), 
                         smc_options = set_smc_options(n_particles = 1000))
```

All the posterior summary methods can be used for `model2`. For example, we can plot the posterior of $\alpha$.


```r
plot(model2)
```

<div class="figure">
<img src="smc_complete_model2_alpha-1.png" alt="Posterior distribution of scale parameter for model 2." height="4cm" />
<p class="caption">Posterior distribution of scale parameter for model 2.</p>
</div>

And we can plot the posterior of the latent ranks of selected items:


```r
plot(model2, parameter = "rho", items = c("shrimp", "sea eel", "tuna"))
```

<div class="figure">
<img src="smc_complete_model2-1.png" alt="Posterior distribution of selected latent rankings for model 2." height="4cm" />
<p class="caption">Posterior distribution of selected latent rankings for model 2.</p>
</div>


Next, assume we get yet another set of rankings later, now of size 1000.


```r
data_batch3 <- sushi_rankings[601:1600, ]
```

We can re-update the model.


```r
model3 <- update_mallows(model2, new_data = setup_rank_data(data_batch3))
```

We can again plot posterior quantities, and the plots reveal that as expected, the posterior uncertainty about the rankings has decreased once we added more data.


```r
plot(model3, parameter = "rho", items = c("shrimp", "sea eel", "tuna"))
```

<div class="figure">
<img src="smc_complete_model3-1.png" alt="Posterior distribution of selected latent rankings for model 3." height="4cm" />
<p class="caption">Posterior distribution of selected latent rankings for model 3.</p>
</div>

Finally, we add a batch with the last data and re-update the model.


```r
data_batch4 <- sushi_rankings[1601:5000, ]
model4 <- update_mallows(model3, 
                         new_data = setup_rank_data(rankings = data_batch4))
```

The posterior uncertainty is now very small:


```r
plot(model4, parameter = "rho", items = c("shrimp", "sea eel", "tuna"))
```

<div class="figure">
<img src="smc_complete_model4_rho-1.png" alt="Posterior distribution of selected latent rankings for model 4." height="4cm" />
<p class="caption">Posterior distribution of selected latent rankings for model 4.</p>
</div>


Below is a comparison of the posterior intervals of the dispersion parameter for each model. Note how the intervals get increasingly narrower as more data is added.


```r
rbind(
  compute_posterior_intervals(model1),
  compute_posterior_intervals(model2), 
  compute_posterior_intervals(model3),
  compute_posterior_intervals(model4)
)
#>   parameter  mean median conf_level          hpdi central_interval
#> 1     alpha 1.774  1.769       95 % [1.603,1.924]    [1.611,1.938]
#> 2     alpha 1.776  1.778       95 % [1.632,1.951]    [1.614,1.936]
#> 3     alpha 1.752  1.752       95 % [1.670,1.825]    [1.673,1.831]
#> 4     alpha 1.707  1.707       95 % [1.667,1.753]    [1.667,1.753]
```

As an assurance that the implementation is correct, we can compare the final model to what we get by running `compute_mallows` on the complete dataset:


```r
mod_bmm <- compute_mallows(
  data = setup_rank_data(rankings = sushi_rankings),
  compute_options = set_compute_options(nmc = 5000, burnin = 1000)
  )
```

We can compare the posteriors for $\alpha$ of the two models. Note that although both are rather wiggly, they agree very well about location and scale.


```r
plot(mod_bmm)
```

<div class="figure">
<img src="smc_complete_mod_bmm-1.png" alt="Posterior distribution of scale parameter for Metropolis-Hastings run on the complete data." height="4cm" />
<p class="caption">Posterior distribution of scale parameter for Metropolis-Hastings run on the complete data.</p>
</div>



```r
plot(model4)
```

<div class="figure">
<img src="smc_complete_model4_alpha-1.png" alt="Posterior distribution of scale parameter for model 4." height="4cm" />
<p class="caption">Posterior distribution of scale parameter for model 4.</p>
</div>

The posterior intervals are also in good agreement.


```r
rbind(
  compute_posterior_intervals(mod_bmm),
  compute_posterior_intervals(model4)
)
#>   parameter  mean median conf_level          hpdi central_interval
#> 1     alpha 1.713  1.713       95 % [1.676,1.753]    [1.669,1.750]
#> 2     alpha 1.707  1.707       95 % [1.667,1.753]    [1.667,1.753]
```

The cumulative probability consensus is also in good agrement:


```r
compute_consensus(model4)
#>    ranking          item cumprob
#> 1        1    fatty tuna   1.000
#> 2        2    salmon roe   1.000
#> 3        3          tuna   1.000
#> 4        4        shrimp   1.000
#> 5        5       sea eel   1.000
#> 6        6     tuna roll   0.878
#> 7        7         squid   1.000
#> 8        8    sea urchin   1.000
#> 9        9           egg   1.000
#> 10      10 cucumber roll   1.000
compute_consensus(mod_bmm)
#>    ranking          item cumprob
#> 1        1    fatty tuna  1.0000
#> 2        2    salmon roe  1.0000
#> 3        3          tuna  1.0000
#> 4        4        shrimp  1.0000
#> 5        5       sea eel  1.0000
#> 6        6     tuna roll  0.9995
#> 7        7         squid  1.0000
#> 8        8    sea urchin  1.0000
#> 9        9           egg  1.0000
#> 10      10 cucumber roll  1.0000
```




## Online learning with partial rankings

The functionality extends directly to partial ranks, including both top-$k$ rankings and rankings missing at random. At the moment, pairwise preferences are not supported, but this will be added in the future.

For this demonstration we shall assume that we can only observe the top-5 ranked items from each user in the `sushi_rankings` dataset.


```r
data_partial <- sushi_rankings
data_partial[data_partial > 5] <- NA
head(data_partial)
#>      shrimp sea eel tuna squid sea urchin salmon roe egg fatty tuna tuna roll cucumber roll
#> [1,]      2      NA   NA     3          4          1   5         NA        NA            NA
#> [2,]      1      NA   NA     4         NA         NA   3          5        NA             2
#> [3,]      2      NA    3     4         NA         NA  NA          1         5            NA
#> [4,]      4      NA    5    NA          1          2  NA          3        NA            NA
#> [5,]      4      NA   NA     5         NA          3   2         NA         1            NA
#> [6,]      4      NA    2    NA         NA          5   1         NA        NA             3
```

Again, assume we start out with a batch of data, this time with 100 rankings:


```r
data_batch1 <- data_partial[1:100, ]
```

We estimate this model using `compute_mallows()`. Since there are `NA`s in the data, `compute_mallows()` will run imputation over the missing ranks.


```r
model1 <- compute_mallows(
  data = setup_rank_data(data_batch1),
  compute_options = set_compute_options(nmc = 10000)
  )
```

The trace plot shows that convergence is reached quickly.


```r
assess_convergence(model1)
```

<div class="figure">
<img src="convergence_smc_partial-1.png" alt="Trace plot for SMC model." height="5cm" />
<p class="caption">Trace plot for SMC model.</p>
</div>

We set the burnin to 300.


```r
model1$burnin <- 300
```

Below is the posterior for $\alpha$ after this initial run:


```r
plot(model1)
```

<div class="figure">
<img src="smc_init_posterior_partial-1.png" alt="Posterior distribution of scale parameter after initial run." height="4cm" />
<p class="caption">Posterior distribution of scale parameter after initial run.</p>
</div>

Next, assume we receive 100 more top-5 rankings:


```r
data_batch2 <- data_partial[101:200, ]
```

We now update the initial model, using SMC. One important thing to notice is that be default, a pseudolikelihood proposal developed by @steinSequentialInferenceMallows2023 is used in the Metropolis-Hastings algorithm for augmented rankings. In contrast, `compute_mallows` uses a uniform proposal. This can be adjusted by setting `aug_method = "uniform"` when calling `set_smc_options`.


```r
model2 <- update_mallows(model1, new_data = setup_rank_data(data_batch2), 
                         smc_options = set_smc_options(n_particles = 1000))
```

Below is the posterior for $\alpha$:


```r
plot(model2)
```

<div class="figure">
<img src="smc_updated_posterior_partial-1.png" alt="Posterior distribution of scale parameter after updating the model based on new rankings." height="4cm" />
<p class="caption">Posterior distribution of scale parameter after updating the model based on new rankings.</p>
</div>


When even more data arrives, we can update the model again. For example, assume we now get a set of complete rankings, with no missingness:


```r
data_batch3 <- sushi_rankings[201:300, ]
```

We update the model just as before:


```r
model3 <- update_mallows(model2, new_data = setup_rank_data(data_batch3))
```


```r
plot(model3)
```

<div class="figure">
<img src="smc_second_updated_posterior_partial-1.png" alt="Posterior distribution of scale parameter after updating the model based on new rankings." height="4cm" />
<p class="caption">Posterior distribution of scale parameter after updating the model based on new rankings.</p>
</div>






## References
