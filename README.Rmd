---
output:
  github_document:
    fig_width: 6
    fig_height: 4
bibliography: ./inst/REFERENCES.bib
link-citations: true
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  eval = TRUE
)
```
# BayesMallows

[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/BayesMallows)](https://cran.r-project.org/package=BayesMallows)
[![R-CMD-check](https://github.com/ocbe-uio/BayesMallows/workflows/R-CMD-check/badge.svg)](https://github.com/ocbe-uio/BayesMallows/actions)
[![Codecov test coverage](https://codecov.io/gh/ocbe-uio/BayesMallows/branch/master/graph/badge.svg)](https://app.codecov.io/gh/ocbe-uio/BayesMallows?branch=master)
[![CodeFactor](https://www.codefactor.io/repository/github/ocbe-uio/bayesmallows/badge/develop)](https://www.codefactor.io/repository/github/ocbe-uio/bayesmallows/overview/develop)

This package provides a general framework for analyzing rank and preference data based on the Bayesian Mallows model first described in @vitelli2018.

## Installation

To install the current release, use

```{r,eval=FALSE}
install.packages("BayesMallows")
```

To install the current development version, use

```{r,eval=FALSE}
# install.packages("remotes")
remotes::install_github("ocbe-uio/BayesMallows")
```

## Basic Usage Example

To get started, load the package with

```{r}
library(BayesMallows)
```

The package comes with several example datasets. The simplest one contains 12 persons' assessments of the weights of 20 potatoes, either by visual inspection (`potato_visual`) or by lifting the potatoes and comparing their relative weights by hand (`potato_weighing`). To fit a Bayesian Mallows model on the `potato_visual` dataset, we do

```{r}
potato_data <- setup_rank_data(potato_visual)
fit <- compute_mallows(data = potato_data)
```

Next, we can see a diagnostic plot for the Metropolis-Hastings algorithm with `assess_convergence()`. The plot below is for the scale parameter, which measures the variation between the individual rankings.

```{r}
assess_convergence(fit)
```

Setting the burnin to 500, we obtain a plot of the posterior distribution of the scale parameter with:

```{r}
plot(fit, burnin = 500)
```


For more examples, please our [R Journal paper](https://journal.r-project.org/archive/2020/RJ-2020-026/index.html), and the function documentation. The use of parallel chains are described in [this vignette](https://ocbe-uio.github.io/BayesMallows/articles/parallel_chains.html).

## The Bayesian Mallows Model

### Methodology

The BayesMallows package currently implements the complete model described in @vitelli2018, which includes a large number of distance metrics, handling of missing ranks and pairwise comparisons, and clustering of users with similar preferences. The extension to non-transitive pairwise comparisons by @crispino2019 is also implemented. In addition, the partition function of the Mallows model can be estimated using the importance sampling algorithm of @vitelli2018 and the asymptotic approximation of @mukherjee2016. For a review of ranking models in general, see @liu2019. @crispino2022 outlines how informative priors can be used within the model. 

Updating of the posterior distribution based on new data, using sequential Monte Carlo methods, is implemented and described in [a separate vignette](https://ocbe-uio.github.io/BayesMallows/articles/SMC-Mallows.html). The computational algorithms are described in further detail in @steinSequentialInferenceMallows2023.

### Applications

Among the current applications, @liu2019b applied the Bayesian Mallows model for providing personalized recommendations based on clicking data, and @barrett2018 used the model of @crispino2019 to analyze listeners' understanding of music. @eliseussenRankbasedBayesianVariable2022 presented an extended model for variable selection in genome-wide transcriptomic analyses.

### Future Extensions

Plans for future extensions of the package include implementation of a variational Bayes algorithm for approximation the posterior distribution. The sequential Monte Carlo algorithms will also be extended to cover a larger part of the model framework, and we will add more options for specifications of prior distributions.

## Citation

If using the BayesMallows package in academic work, please cite @sorensen2020, in addition to the relevant methodological papers.

```{r}
citation("BayesMallows")
```


## Contribution

This is an open source project, and all contributions are welcome. Feel free to open an [Issue](https://github.com/ocbe-uio/BayesMallows/issues), a [Pull Request](https://github.com/ocbe-uio/BayesMallows/pulls), or to e-mail us.

## References
