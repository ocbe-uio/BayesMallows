---
output:
  github_document:
    fig_width: 6
    fig_height: 4
bibliography: ./inst/REFERENCES.bib
link-citations: true
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  eval = TRUE
)
```
# BayesMallows

[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/BayesMallows)](https://cran.r-project.org/package=BayesMallows)
[![R-CMD-check](https://github.com/ocbe-uio/BayesMallows/workflows/R-CMD-check/badge.svg)](https://github.com/ocbe-uio/BayesMallows/actions)
[![Codecov test coverage](https://codecov.io/gh/ocbe-uio/BayesMallows/graph/badge.svg)](https://app.codecov.io/gh/ocbe-uio/BayesMallows)
[![CodeFactor](https://www.codefactor.io/repository/github/ocbe-uio/bayesmallows/badge/master)](https://www.codefactor.io/repository/github/ocbe-uio/bayesmallows/overview/master)
This package provides a general framework for analyzing rank and preference data based on the Bayesian Mallows model.

## Installation

To install the current release, use

```{r,eval=FALSE}
install.packages("BayesMallows")
```

To install the current development version, use

```{r,eval=FALSE}
# install.packages("remotes")
remotes::install_github("ocbe-uio/BayesMallows")
```

## Basic Usage Example

To get started, load the package with

```{r}
library(BayesMallows)
set.seed(123)
```



The package comes with several example datasets. The simplest one contains 12 persons' assessments of the weights of 20 potatoes, either by visual inspection (`potato_visual`) or by lifting the potatoes and comparing their relative weights by hand (`potato_weighing`).

### Metropolis-Hastings Algorithm

To fit a Bayesian Mallows model on the `potato_visual` dataset using the Metropolis-Hastings algorithm first described in @vitelli2018, we do

```{r}
potato_data <- setup_rank_data(potato_visual)
fit <- compute_mallows(data = potato_data)
```

Next, we can see a diagnostic plot for the Metropolis-Hastings algorithm with `assess_convergence()`. The plot below is for the scale parameter, which measures the variation between the individual rankings.

```{r}
assess_convergence(fit)
```

Setting the burnin to 500, we obtain a plot of the posterior distribution of the scale parameter with:

```{r}
burnin(fit) <- 500
plot(fit)
```


For more examples, please see our [the introductory vignette](https://ocbe-uio.github.io/BayesMallows/articles/BayesMallows.html), and the function documentation. The use of parallel chains are described in [this vignette](https://ocbe-uio.github.io/BayesMallows/articles/parallel_chains.html).

### Sequential Monte Carlo Algorithm

The package also supports updating a Bayesian Mallows model using sequential Monte Carlo, with the algorithm described in @steinSequentialInferenceMallows2023. For example, in order to update the model fitted above with the potato ranks based on comparing their relative weights by hand, we do

```{r}
new_data <- setup_rank_data(rankings = potato_weighing)
updated_fit <- update_mallows(model = fit, new_data = new_data)
```

We can go on to plot the posterior distribution of the scale parameter for this updated model.

```{r}
plot(updated_fit)
```

Sequential Monte Carlo can typically be useful when new data arrives in batches, as it does not require the Metropolis-Hastings algorithm to be rerun. See [this vignette](https://ocbe-uio.github.io/BayesMallows/articles/SMC-Mallows.html) for more information.


## The Bayesian Mallows Model

### Methodology

The BayesMallows package currently implements the complete model described in @vitelli2018, which includes a large number of distance metrics, handling of missing ranks and pairwise comparisons, and clustering of users with similar preferences. The extension to non-transitive pairwise comparisons by @crispino2019 is also implemented. In addition, the partition function of the Mallows model can be estimated using the importance sampling algorithm of @vitelli2018 and the asymptotic approximation of @mukherjee2016. For a review of ranking models in general, see @liu2019. @crispino2022 outlines how informative priors can be used within the model.

Updating of the posterior distribution based on new data, using sequential Monte Carlo methods, is implemented and described in [a separate vignette](https://ocbe-uio.github.io/BayesMallows/articles/SMC-Mallows.html). The computational algorithms are described in further detail in @steinSequentialInferenceMallows2023.

### Applications

Among the current applications, @liu2019b applied the Bayesian Mallows model for providing personalized recommendations based on clicking data, and @barrett2018 used the model of @crispino2019 to analyze listeners' understanding of music. @eliseussenRankbasedBayesianVariable2022 presented an extended model for variable selection in genome-wide transcriptomic analyses.

### Future Extensions

Plans for future extensions of the package include implementation of a variational Bayes algorithm for approximation the posterior distribution. The sequential Monte Carlo algorithms will also be extended to cover a larger part of the model framework, and we will add more options for specifications of prior distributions.

## Compilation with Thread Building Blocks (TBB)

Parts of the underlying C++ code can be easily parallelized. We have support for this through [oneAPI Threading Building Blocks](https://github.com/oneapi-src/oneTBB). If you want to make use of this, build the package from source with the `-ltbb` argument. On an M1 Mac this can be achieved by first installing TBB through `brew install tbb` and then adding the following line to `~/.R/Makevars`:

```{sh, eval=FALSE}
CXX17=g++-13 -I/opt/homebrew/include -L/opt/homebrew/lib -ltbb
```

The arguments on other platforms should be similar. If TBB is not available, the package will fall back on sequential processing.

## Citation

If using the BayesMallows package in academic work, please cite @sorensen2020, in addition to the relevant methodological papers.

```{r}
citation("BayesMallows")
```


## Contribution

This is an open source project, and all contributions are welcome. Feel free to open an [Issue](https://github.com/ocbe-uio/BayesMallows/issues), a [Pull Request](https://github.com/ocbe-uio/BayesMallows/pulls), or to e-mail us.

## References
