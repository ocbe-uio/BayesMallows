<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Introduction ‚Ä¢ BayesMallows</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">BayesMallows</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">2.2.3</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item"><a class="nav-link" href="../articles/BayesMallows.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/parallel_chains.html">MCMC with Parallel Chains</a></li>
    <li><a class="dropdown-item" href="../articles/SMC-Mallows.html">Sequential Monte Carlo for the Bayesian Mallows model</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/ocbe-uio/BayesMallows/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Introduction</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/ocbe-uio/BayesMallows/blob/v2.2.3/vignettes/BayesMallows.Rmd" class="external-link"><code>vignettes/BayesMallows.Rmd</code></a></small>
      <div class="d-none name"><code>BayesMallows.Rmd</code></div>
    </div>

    
    
<p>This vignette contains update syntax for the code examples in <span class="citation">S√∏rensen et al. (<a href="#ref-sorensen2020">2020</a>)</span>, since both the underlying
code and the user interface are continuously evolving. We refer to <span class="citation">S√∏rensen et al. (<a href="#ref-sorensen2020">2020</a>)</span> for notation and all other
details about the models and algorithms.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/ocbe-uio/BayesMallows" class="external-link">BayesMallows</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span></code></pre></div>
<div class="section level2">
<h2 id="analysis-of-complete-rankings">Analysis of complete rankings<a class="anchor" aria-label="anchor" href="#analysis-of-complete-rankings"></a>
</h2>
<p>We illustrate the case of complete rankings with the potato datasets
described in Section 4 of <span class="citation">(<a href="#ref-liu2019">Liu et al. 2019</a>)</span>. In short, a bag of 20
potatoes was bought, and 12 assessors were asked to rank the potatoes by
weight, first by visual inspection, and next by holding the potatoes in
hand. These datasets are available in <code>BayesMallows</code> as
matrices with names <code>potato_weighing</code> and
<code>potato_visual</code>, respectively. The true ranking of the
potatoes‚Äô weights is available in the vector
<code>potato_true_ranking</code>. In general,
<code>compute_mallows</code> expects ranking datasets to have one row
for each assessor and one column for each item. Each row has to be a
proper permutation, possibly with missing values. We are interested in
the posterior distribution of both the level of agreement between
assessors, as described by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
and in the latent ranking of the potatoes, as described by
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõí</mi><annotation encoding="application/x-tex">\boldsymbol{\rho}</annotation></semantics></math>.
We refer to the attached replication script for random number seeds for
exact reproducibility.</p>
<p>We start by defining our data object, which in this case consists of
complete rankings.</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">complete_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/setup_rank_data.html">setup_rank_data</a></span><span class="op">(</span>rankings <span class="op">=</span> <span class="va">potato_visual</span><span class="op">)</span></span></code></pre></div>
<p>First, we do a test run to check convergence of the MCMC algorithm,
and then get trace plots with <code>assess_convergence</code>.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmm_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_mallows.html">compute_mallows</a></span><span class="op">(</span>data <span class="op">=</span> <span class="va">complete_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="../reference/assess_convergence.html">assess_convergence</a></span><span class="op">(</span><span class="va">bmm_test</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="complete_data_diagnostic_alpha-1.png" alt="Trace plot for scale parameter."><div class="figcaption">Trace plot for scale parameter.</div>
</div>
<p>By default, <code>assess_convergence</code> returns a trace plot for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>,
shown in the figure above. The algorithm seems to be mixing well after
around 500 iterations. Next, we study the convergence of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõí</mi><annotation encoding="application/x-tex">\mathbf{\rho}</annotation></semantics></math>.
To avoid overly complex plots, we pick potatoes
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>‚àí</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">1-5</annotation></semantics></math>
by specifying this in the <code>items</code> argument.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/assess_convergence.html">assess_convergence</a></span><span class="op">(</span><span class="va">bmm_test</span>, parameter <span class="op">=</span> <span class="st">"rho"</span>, items <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="complete_data_diagnostic_rho-1.png" alt="Trace plot for modal ranking."><div class="figcaption">Trace plot for modal ranking.</div>
</div>
<p>The plot shows that the MCMC algorithm seems to have converged after
around 1,000 iterations.</p>
<p>From the trace plots, we decide to discard the first 1,000 MCMC
samples as burn-in. We rerun the algorithm to get 20,000 samples after
burn-in. The object <code>bmm_visual</code> has <code>S3</code> class
<code>BayesMallows</code>, so we plot the posterior distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
with <code>plot.BayesMallows</code>.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmm_visual</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_mallows.html">compute_mallows</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">complete_data</span>, </span>
<span>  compute_options <span class="op">=</span> <span class="fu"><a href="../reference/set_compute_options.html">set_compute_options</a></span><span class="op">(</span>nmc <span class="op">=</span> <span class="fl">21000</span>, burnin <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">bmm_visual</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="complete_data_model-1.png" alt="Posterior for scale parameter."><div class="figcaption">Posterior for scale parameter.</div>
</div>
<p>We can also get posterior credible intervals for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
using <code>compute_posterior_intervals</code>, which returns both
highest posterior density intervals (HPDI) and central intervals in a
<code>data.frame</code>.</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/compute_posterior_intervals.html">compute_posterior_intervals</a></span><span class="op">(</span><span class="va">bmm_visual</span>, decimals <span class="op">=</span> <span class="fl">1L</span><span class="op">)</span></span>
<span><span class="co">#&gt;   parameter mean median       hpdi central_interval</span></span>
<span><span class="co">#&gt; 1     alpha 10.9   10.9 [9.5,12.3]       [9.5,12.3]</span></span></code></pre></div>
<p>Next, we can go on to study the posterior distribution of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõí</mi><annotation encoding="application/x-tex">\boldsymbol{\rho}</annotation></semantics></math>.
If the argument is not provided, and the number of items exceeds five,
five items are picked at random for plotting. To show all potatoes, we
explicitly set .</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">bmm_visual</span>, parameter <span class="op">=</span> <span class="st">"rho"</span>, items <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">20</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="complete_data_posterior_rho-1.png" alt="Posterior for modal ranking."><div class="figcaption">Posterior for modal ranking.</div>
</div>
<div class="section level3">
<h3 id="jumping-over-the-scale-parameter">Jumping over the scale parameter<a class="anchor" aria-label="anchor" href="#jumping-over-the-scale-parameter"></a>
</h3>
<p>Updating
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
in every step of the MCMC algorithm may not be necessary, as the number
of posterior samples typically is more than large enough to obtain good
estimates of its posterior distribution. With the
<code>alpha_jump</code> argument, we can tell the MCMC algorithm to
update
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
only every <code>alpha_jump</code>-th iteration. To update
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
every 10th time
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõí</mi><annotation encoding="application/x-tex">\boldsymbol{\rho}</annotation></semantics></math>
is updated, we do</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmm_visual</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_mallows.html">compute_mallows</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">complete_data</span>, </span>
<span>  compute_options <span class="op">=</span> </span>
<span>    <span class="fu"><a href="../reference/set_compute_options.html">set_compute_options</a></span><span class="op">(</span>nmc <span class="op">=</span> <span class="fl">21000</span>, burnin <span class="op">=</span> <span class="fl">1000</span>, alpha_jump <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="other-distance-metric">Other distance metric<a class="anchor" aria-label="anchor" href="#other-distance-metric"></a>
</h3>
<p>By default, <code>compute_mallows</code> uses the footrule distance,
but the user can also choose to use Cayley, Kendall, Hamming, Spearman,
or Ulam distance. Running the same analysis of the potato data with
Spearman distance is done with the command</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_mallows.html">compute_mallows</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">complete_data</span>, </span>
<span>  model_options <span class="op">=</span> <span class="fu"><a href="../reference/set_model_options.html">set_model_options</a></span><span class="op">(</span>metric <span class="op">=</span> <span class="st">"spearman"</span><span class="op">)</span>,</span>
<span>  compute_options <span class="op">=</span> <span class="fu"><a href="../reference/set_compute_options.html">set_compute_options</a></span><span class="op">(</span>nmc <span class="op">=</span> <span class="fl">21000</span>, burnin <span class="op">=</span> <span class="fl">1000</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>For the particular case of Spearman distance,
<code>BayesMallows</code> only has integer sequences for computing the
exact partition function with 14 or fewer items. In this case a
precomputed importance sampling estimate is part of the package, and
used instead.</p>
</div>
</div>
<div class="section level2">
<h2 id="analysis-of-preference-data">Analysis of preference data<a class="anchor" aria-label="anchor" href="#analysis-of-preference-data"></a>
</h2>
<p>Unless the argument <code>error_model</code> to
<code>set_model_options</code> is set, pairwise preference data are
assumed to be consistent within each assessor. These data should be
provided in a dataframe with the following three columns, with one row
per pairwise comparison:</p>
<ul>
<li>
<code>assessor</code> is an identifier for the assessor; either a
numeric vector containing the assessor index, or a character vector
containing the unique name of the assessor.</li>
<li>
<code>bottom_item</code> is a numeric vector containing the index of
the item that was disfavored in each pairwise comparison.</li>
<li>
<code>top_item</code> is a numeric vector containing the index of
the item that was preferred in each pairwise comparison.</li>
</ul>
<p>A dataframe with this structure can be given in the
<code>preferences</code> argument to <code>setup_rank_data</code>, which
will generate the full set of implied rankings for each assessor as well
as an initial ranking matrix consistent with the pairwise
preferences.</p>
<p>We illustrate with the beach preference data containing stated
pairwise preferences between random subsets of 15 images of beaches, by
60 assessors <span class="citation">(<a href="#ref-vitelli2018">Vitelli
et al. 2018</a>)</span>. This dataset is provided in the dataframe
<code>beach_preferences</code>, whose first six rows are shown
below:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">beach_preferences</span><span class="op">)</span></span>
<span><span class="co">#&gt;   assessor bottom_item top_item</span></span>
<span><span class="co">#&gt; 1        1           2       15</span></span>
<span><span class="co">#&gt; 2        1           5        3</span></span>
<span><span class="co">#&gt; 3        1          13        3</span></span>
<span><span class="co">#&gt; 4        1           4        7</span></span>
<span><span class="co">#&gt; 5        1           5       15</span></span>
<span><span class="co">#&gt; 6        1          12        6</span></span></code></pre></div>
<p>We can define a rank data object based on these preferences.</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">beach_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/setup_rank_data.html">setup_rank_data</a></span><span class="op">(</span>preferences <span class="op">=</span> <span class="va">beach_preferences</span><span class="op">)</span></span></code></pre></div>
<p>It is instructive to compare the computed transitive closure to the
stated preferences. Let‚Äôs do this for all preferences stated by assessor
1 involving beach 2. We first look at the raw preferences.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">beach_preferences</span>, <span class="va">assessor</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">&amp;</span> <span class="op">(</span><span class="va">bottom_item</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">|</span> <span class="va">top_item</span> <span class="op">==</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;   assessor bottom_item top_item</span></span>
<span><span class="co">#&gt; 1        1           2       15</span></span></code></pre></div>
<p>We then use the function <code>get_transitive_closure</code> to
obtain the transitive closure, and then focus on the same subset:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">tc</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/get_transitive_closure.html">get_transitive_closure</a></span><span class="op">(</span><span class="va">beach_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">tc</span>, <span class="va">assessor</span> <span class="op">==</span> <span class="fl">1</span> <span class="op">&amp;</span> <span class="op">(</span><span class="va">bottom_item</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">|</span> <span class="va">top_item</span> <span class="op">==</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;    assessor bottom_item top_item</span></span>
<span><span class="co">#&gt; 11        1           2        6</span></span>
<span><span class="co">#&gt; 44        1           2       15</span></span></code></pre></div>
<p>Assessor 1 has performed only one direct comparison involving beach
2, in which the assessor stated that beach 15 is preferred to beach 2.
The implied orderings, on the other hand, contain two preferences
involving beach 2. In addition to the statement that beach 15 is
preferred to beach 2, all the other orderings stated by assessor 1 imply
that this assessor prefers beach 6 to beach 2.</p>
<div class="section level3">
<h3 id="convergence-diagnostics">Convergence diagnostics<a class="anchor" aria-label="anchor" href="#convergence-diagnostics"></a>
</h3>
<p>As with the potato data, we can do a test run to assess the
convergence of the MCMC algorithm. This time we use the
<code>beach_data</code> object that we generated above, based on the
stated preferences. We also set <code>save_aug = TRUE</code> to save the
augmented rankings in each MCMC step, hence letting us assess the
convergence of the augmented rankings.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmm_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_mallows.html">compute_mallows</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">beach_data</span>,</span>
<span>  compute_options <span class="op">=</span> <span class="fu"><a href="../reference/set_compute_options.html">set_compute_options</a></span><span class="op">(</span>save_aug <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Running <code>assess_convergence</code> for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõí</mi><annotation encoding="application/x-tex">\boldsymbol{\rho}</annotation></semantics></math>
shows good convergence after 1000 iterations.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/assess_convergence.html">assess_convergence</a></span><span class="op">(</span><span class="va">bmm_test</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="preferences_alpha_trace-1.png" alt="Trace plot for scale parameter."><div class="figcaption">Trace plot for scale parameter.</div>
</div>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/assess_convergence.html">assess_convergence</a></span><span class="op">(</span><span class="va">bmm_test</span>, parameter <span class="op">=</span> <span class="st">"rho"</span>, items <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="preferences_rho_trace-1.png" alt="Trace plot for modal ranking."><div class="figcaption">Trace plot for modal ranking.</div>
</div>
<p>To check the convergence of the data augmentation scheme, we need to
set <code>parameter = "Rtilde"</code>, and also specify which items and
assessors to plot. Let us start by considering items 2, 6, and 15 for
assessor 1, which we studied above.</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/assess_convergence.html">assess_convergence</a></span><span class="op">(</span></span>
<span>  <span class="va">bmm_test</span>, parameter <span class="op">=</span> <span class="st">"Rtilde"</span>, items <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">15</span><span class="op">)</span>, assessors <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="preferences_augmented_rankings-1.png" alt="Trace plot for augmented rankings."><div class="figcaption">Trace plot for augmented rankings.</div>
</div>
<p>The convergence plot illustrates how the augmented rankings vary,
while also obeying their implied ordering.</p>
<p>By further investigation of the transitive closure, we find that no
orderings are implied between beach 1 and beach 15 for assessor 2. That
is, the following statement returns zero rows.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">tc</span>, <span class="va">assessor</span> <span class="op">==</span> <span class="fl">2</span> <span class="op">&amp;</span> <span class="va">bottom_item</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">15</span><span class="op">)</span> <span class="op">&amp;</span> <span class="va">top_item</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">15</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] assessor    bottom_item top_item   </span></span>
<span><span class="co">#&gt; &lt;0 rows&gt; (or 0-length row.names)</span></span></code></pre></div>
<p>With the following command, we create trace plots to confirm
this:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/assess_convergence.html">assess_convergence</a></span><span class="op">(</span></span>
<span>  <span class="va">bmm_test</span>, parameter <span class="op">=</span> <span class="st">"Rtilde"</span>, items <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">15</span><span class="op">)</span>, assessors <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="preferences_augmented_rankings_free-1.png" alt="Trace plot for augmented rankings where items have not been compared."><div class="figcaption">Trace plot for augmented rankings where items
have not been compared.</div>
</div>
<p>As expected, the traces of the augmented rankings for beach 1 and 15
for assessor 2 do cross each other, since no ordering is implied between
them.</p>
<p>Ideally, we should look at trace plots for augmented ranks for more
assessors to be sure that the algorithm is close to convergence. We can
plot assessors 1-8 by setting <code>assessors = 1:8</code>. We also
quite arbitrarily pick items 13-15, but the same procedure can be
repeated for other items.</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/assess_convergence.html">assess_convergence</a></span><span class="op">(</span></span>
<span>  <span class="va">bmm_test</span>, parameter <span class="op">=</span> <span class="st">"Rtilde"</span>, items <span class="op">=</span> <span class="fl">13</span><span class="op">:</span><span class="fl">15</span>, assessors <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">8</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="preferences_augmented_rankings_many-1.png" alt="Trace plots for items 13-15 and assessors 1-8."><div class="figcaption">Trace plots for items 13-15 and assessors
1-8.</div>
</div>
<p>The plot indicates good mixing.</p>
</div>
<div class="section level3">
<h3 id="posterior-distributions">Posterior distributions<a class="anchor" aria-label="anchor" href="#posterior-distributions"></a>
</h3>
<p>Based on the convergence diagnostics, and being fairly conservative,
we discard the first 2,000 MCMC iterations as burn-in, and take 20,000
additional samples.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmm_beaches</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_mallows.html">compute_mallows</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">beach_data</span>,</span>
<span>  compute_options <span class="op">=</span> </span>
<span>    <span class="fu"><a href="../reference/set_compute_options.html">set_compute_options</a></span><span class="op">(</span>nmc <span class="op">=</span> <span class="fl">22000</span>, burnin <span class="op">=</span> <span class="fl">2000</span>, save_aug <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The posterior distributions of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõí</mi><annotation encoding="application/x-tex">\boldsymbol{\rho}</annotation></semantics></math>
can be studied as shown in the previous sections. Posterior intervals
for the latent rankings of each beach are obtained with
<code>compute_posterior_intervals</code>:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/compute_posterior_intervals.html">compute_posterior_intervals</a></span><span class="op">(</span><span class="va">bmm_beaches</span>, parameter <span class="op">=</span> <span class="st">"rho"</span><span class="op">)</span></span>
<span><span class="co">#&gt;    parameter    item mean median    hpdi central_interval</span></span>
<span><span class="co">#&gt; 1        rho  Item 1    7      7     [7]              [7]</span></span>
<span><span class="co">#&gt; 2        rho  Item 2   15     15    [15]             [15]</span></span>
<span><span class="co">#&gt; 3        rho  Item 3    3      3   [3,4]            [3,4]</span></span>
<span><span class="co">#&gt; 4        rho  Item 4   12     12 [11,13]          [11,14]</span></span>
<span><span class="co">#&gt; 5        rho  Item 5    9      9  [8,10]           [8,10]</span></span>
<span><span class="co">#&gt; 6        rho  Item 6    2      2   [1,2]            [1,2]</span></span>
<span><span class="co">#&gt; 7        rho  Item 7    8      8   [8,9]           [8,10]</span></span>
<span><span class="co">#&gt; 8        rho  Item 8   12     12 [11,13]          [11,14]</span></span>
<span><span class="co">#&gt; 9        rho  Item 9    1      1   [1,2]            [1,2]</span></span>
<span><span class="co">#&gt; 10       rho Item 10    6      6   [5,6]            [5,6]</span></span>
<span><span class="co">#&gt; 11       rho Item 11    4      4   [3,4]            [3,5]</span></span>
<span><span class="co">#&gt; 12       rho Item 12   13     13 [12,14]          [12,14]</span></span>
<span><span class="co">#&gt; 13       rho Item 13   10     10  [9,10]           [9,10]</span></span>
<span><span class="co">#&gt; 14       rho Item 14   13     14 [11,14]          [11,14]</span></span>
<span><span class="co">#&gt; 15       rho Item 15    5      5   [4,5]            [4,6]</span></span></code></pre></div>
<p>We can also rank the beaches according to their cumulative
probability (CP) consensus <span class="citation">(<a href="#ref-vitelli2018">Vitelli et al. 2018</a>)</span> and their
maximum posterior (MAP) rankings. This is done with the function
<code>compute_consensus</code>, and the following call returns the CP
consensus:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/compute_consensus.html">compute_consensus</a></span><span class="op">(</span><span class="va">bmm_beaches</span>, type <span class="op">=</span> <span class="st">"CP"</span><span class="op">)</span></span>
<span><span class="co">#&gt;      cluster ranking    item cumprob</span></span>
<span><span class="co">#&gt; 1  Cluster 1       1  Item 9 0.89815</span></span>
<span><span class="co">#&gt; 2  Cluster 1       2  Item 6 1.00000</span></span>
<span><span class="co">#&gt; 3  Cluster 1       3  Item 3 0.72665</span></span>
<span><span class="co">#&gt; 4  Cluster 1       4 Item 11 0.95160</span></span>
<span><span class="co">#&gt; 5  Cluster 1       5 Item 15 0.95400</span></span>
<span><span class="co">#&gt; 6  Cluster 1       6 Item 10 0.97645</span></span>
<span><span class="co">#&gt; 7  Cluster 1       7  Item 1 1.00000</span></span>
<span><span class="co">#&gt; 8  Cluster 1       8  Item 7 0.62585</span></span>
<span><span class="co">#&gt; 9  Cluster 1       9  Item 5 0.85950</span></span>
<span><span class="co">#&gt; 10 Cluster 1      10 Item 13 1.00000</span></span>
<span><span class="co">#&gt; 11 Cluster 1      11  Item 4 0.46870</span></span>
<span><span class="co">#&gt; 12 Cluster 1      12  Item 8 0.84435</span></span>
<span><span class="co">#&gt; 13 Cluster 1      13 Item 12 0.61905</span></span>
<span><span class="co">#&gt; 14 Cluster 1      14 Item 14 0.99665</span></span>
<span><span class="co">#&gt; 15 Cluster 1      15  Item 2 1.00000</span></span></code></pre></div>
<p>The column <code>cumprob</code> shows the probability of having the
given rank or lower. Looking at the second row, for example, this means
that beach 6 has probability 1 of having latent rank
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÅ</mi><mn>6</mn></msub><mo>‚â§</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">\rho_{6} \leq 2</annotation></semantics></math>.
Next, beach 3 has probability 0.738 of having latent rank
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>œÅ</mi><mn>3</mn></msub><mo>‚â§</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">\rho_{3}\leq 3</annotation></semantics></math>.
This is an example of how the Bayesian framework can be used to not only
rank items, but also to give posterior assessments of the uncertainty of
the rankings. The MAP consensus is obtained similarly, by setting
<code>type = "MAP"</code>.</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/compute_consensus.html">compute_consensus</a></span><span class="op">(</span><span class="va">bmm_beaches</span>, type <span class="op">=</span> <span class="st">"MAP"</span><span class="op">)</span></span>
<span><span class="co">#&gt;      cluster map_ranking    item probability</span></span>
<span><span class="co">#&gt; 1  Cluster 1           1  Item 9     0.04955</span></span>
<span><span class="co">#&gt; 2  Cluster 1           2  Item 6     0.04955</span></span>
<span><span class="co">#&gt; 3  Cluster 1           3  Item 3     0.04955</span></span>
<span><span class="co">#&gt; 4  Cluster 1           4 Item 11     0.04955</span></span>
<span><span class="co">#&gt; 5  Cluster 1           5 Item 15     0.04955</span></span>
<span><span class="co">#&gt; 6  Cluster 1           6 Item 10     0.04955</span></span>
<span><span class="co">#&gt; 7  Cluster 1           7  Item 1     0.04955</span></span>
<span><span class="co">#&gt; 8  Cluster 1           8  Item 7     0.04955</span></span>
<span><span class="co">#&gt; 9  Cluster 1           9  Item 5     0.04955</span></span>
<span><span class="co">#&gt; 10 Cluster 1          10 Item 13     0.04955</span></span>
<span><span class="co">#&gt; 11 Cluster 1          11  Item 4     0.04955</span></span>
<span><span class="co">#&gt; 12 Cluster 1          12  Item 8     0.04955</span></span>
<span><span class="co">#&gt; 13 Cluster 1          13 Item 14     0.04955</span></span>
<span><span class="co">#&gt; 14 Cluster 1          14 Item 12     0.04955</span></span>
<span><span class="co">#&gt; 15 Cluster 1          15  Item 2     0.04955</span></span></code></pre></div>
<p>Keeping in mind that the ranking of beaches is based on sparse
pairwise preferences, we can also ask: for beach
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>i</mi><annotation encoding="application/x-tex">i</annotation></semantics></math>,
what is the probability of being ranked
top-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>
by assessor
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>,
and what is the probability of having latent rank among the
top-<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>k</mi><annotation encoding="application/x-tex">k</annotation></semantics></math>.
The function <code>plot_top_k</code> plots these probabilities. By
default, it sets <code>k = 3</code>, so a heatplot of the probability of
being ranked top-3 is obtained with the call:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_top_k.html">plot_top_k</a></span><span class="op">(</span><span class="va">bmm_beaches</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="preferences_top_k-1.png" alt="Top-3 rankings for beach preferences."><div class="figcaption">Top-3 rankings for beach preferences.</div>
</div>
<p>The plot shows, for each beach as indicated on the left axis, the
probability that assessor
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>j</mi><annotation encoding="application/x-tex">j</annotation></semantics></math>
ranks the beach among top-3. For example, we see that assessor 1 has a
very low probability of ranking beach 9 among her top-3, while assessor
3 has a very high probability of doing this.</p>
<p>The function <code>predict_top_k</code> returns a dataframe with all
the underlying probabilities. For example, in order to find all the
beaches that are among the top-3 of assessors 1-5 with more than 90 %
probability, we would do:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="fu"><a href="../reference/predict_top_k.html">predict_top_k</a></span><span class="op">(</span><span class="va">bmm_beaches</span><span class="op">)</span>, <span class="va">prob</span> <span class="op">&gt;</span> <span class="fl">.9</span> <span class="op">&amp;</span> <span class="va">assessor</span> <span class="op"><a href="https://rdrr.io/r/base/match.html" class="external-link">%in%</a></span> <span class="fl">1</span><span class="op">:</span><span class="fl">5</span><span class="op">)</span></span>
<span><span class="co">#&gt;     assessor    item    prob</span></span>
<span><span class="co">#&gt; 301        1  Item 6 0.99435</span></span>
<span><span class="co">#&gt; 303        3  Item 6 0.99600</span></span>
<span><span class="co">#&gt; 305        5  Item 6 0.97605</span></span>
<span><span class="co">#&gt; 483        3  Item 9 1.00000</span></span>
<span><span class="co">#&gt; 484        4  Item 9 0.99975</span></span>
<span><span class="co">#&gt; 601        1 Item 11 0.95030</span></span></code></pre></div>
<p>Note that assessor 2 does not appear in this table, i.e., there are
no beaches for which we are at least 90 % certain that the beach is
among assessor 2‚Äôs top-3.</p>
</div>
</div>
<div class="section level2">
<h2 id="clustering">Clustering<a class="anchor" aria-label="anchor" href="#clustering"></a>
</h2>
<p><code>BayesMallows</code> comes with a set of sushi preference data,
in which 5,000 assessors each have ranked a set of 10 types of sushi
<span class="citation">(<a href="#ref-kamishima2003">Kamishima
2003</a>)</span>. It is interesting to see if we can find subsets of
assessors with similar preferences. The sushi dataset was analyzed with
the BMM by <span class="citation">Vitelli et al. (<a href="#ref-vitelli2018">2018</a>)</span>, but the results in that paper
differ somewhat from those obtained here, due to a bug in the function
that was used to sample cluster probabilities from the Dirichlet
distribution. We start by defining the data object.</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sushi_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/setup_rank_data.html">setup_rank_data</a></span><span class="op">(</span><span class="va">sushi_rankings</span><span class="op">)</span></span></code></pre></div>
<div class="section level3">
<h3 id="convergence-diagnostics-1">Convergence diagnostics<a class="anchor" aria-label="anchor" href="#convergence-diagnostics-1"></a>
</h3>
<p>The function <code>compute_mallows_mixtures</code> computes multiple
Mallows models with different numbers of mixture components. It returns
a list of models of class <code>BayesMallowsMixtures</code>, in which
each list element contains a model with a given number of mixture
components. Its arguments are <code>n_clusters</code>, which specifies
the number of mixture components to compute, an optional parameter
<code>cl</code> which can be set to the return value of the
<code>makeCluster</code> function in the <code>parallel</code> package,
and an ellipsis (<code>...</code>) for passing on arguments to
<code>compute_mallows</code>.</p>
<p>Hypothesizing that we may not need more than 10 clusters to find a
useful partitioning of the assessors, we start by doing test runs with
1, 4, 7, and 10 mixture components in order to assess convergence. We
set the number of Monte Carlo samples to 5,000, and since this is a test
run, we do not save within-cluster distances from each MCMC iteration
and hence set <code>include_wcd = FALSE</code>.</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="st">"parallel"</span><span class="op">)</span></span>
<span><span class="va">cl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html" class="external-link">makeCluster</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html" class="external-link">detectCores</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_mallows_mixtures.html">compute_mallows_mixtures</a></span><span class="op">(</span></span>
<span>  n_clusters <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">4</span>, <span class="fl">7</span>, <span class="fl">10</span><span class="op">)</span>,</span>
<span>  data <span class="op">=</span> <span class="va">sushi_data</span>,</span>
<span>  compute_options <span class="op">=</span> <span class="fu"><a href="../reference/set_compute_options.html">set_compute_options</a></span><span class="op">(</span>nmc <span class="op">=</span> <span class="fl">5000</span>, include_wcd <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span>,</span>
<span>  cl <span class="op">=</span> <span class="va">cl</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html" class="external-link">stopCluster</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span></span></code></pre></div>
<p>The function <code>assess_convergence</code> automatically creates a
grid plot when given an object of class
<code>BayesMallowsMixtures</code>, so we can check the convergence of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
with the command</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/assess_convergence.html">assess_convergence</a></span><span class="op">(</span><span class="va">bmm</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="cluster_trace_alpha-1.png" alt="Trace plots for scale parameters."><div class="figcaption">Trace plots for scale parameters.</div>
</div>
<p>The resulting plot shows that all the chains seem to be close to
convergence quite quickly. We can also make sure that the posterior
distributions of the cluster probabilities
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>œÑ</mi><mi>c</mi></msub><annotation encoding="application/x-tex">\tau_{c}</annotation></semantics></math>,
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>c</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>C</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(c = 1, \dots, C)</annotation></semantics></math>
have converged properly, by setting
<code>parameter = "cluster_probs"</code>.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/assess_convergence.html">assess_convergence</a></span><span class="op">(</span><span class="va">bmm</span>, parameter <span class="op">=</span> <span class="st">"cluster_probs"</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="cluster_trace_probs-1.png" alt="Trace plots for cluster assignment probabilities."><div class="figcaption">Trace plots for cluster assignment
probabilities.</div>
</div>
<p>Note that with only one cluster, the cluster probability is fixed at
the value 1, while for other number of mixture components, the chains
seem to be mixing well.</p>
</div>
<div class="section level3">
<h3 id="deciding-on-the-number-of-mixture-components">Deciding on the number of mixture components<a class="anchor" aria-label="anchor" href="#deciding-on-the-number-of-mixture-components"></a>
</h3>
<p>Given the convergence assessment of the previous section, we are
fairly confident that a burn-in of 1,000 is sufficient. We run 40,000
additional iterations, and try from 1 to 10 mixture components. Our goal
is now to determine the number of mixture components to use, and in
order to create an elbow plot, we set <code>include_wcd = TRUE</code> to
compute the within-cluster distances in each step of the MCMC algorithm.
Since the posterior distributions of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>œÅ</mi><mi>c</mi></msub><annotation encoding="application/x-tex">\rho_{c}</annotation></semantics></math>
(<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mo>=</mo><mn>1</mn><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><mi>C</mi></mrow><annotation encoding="application/x-tex">c = 1,\dots,C</annotation></semantics></math>)
are highly peaked, we save some memory by only saving every 10th value
of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõí</mi><annotation encoding="application/x-tex">\boldsymbol{\rho}</annotation></semantics></math>
by setting <code>rho_thinning = 10</code>.</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html" class="external-link">makeCluster</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/parallel/detectCores.html" class="external-link">detectCores</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">bmm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_mallows_mixtures.html">compute_mallows_mixtures</a></span><span class="op">(</span></span>
<span>  n_clusters <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, </span>
<span>  data <span class="op">=</span> <span class="va">sushi_data</span>,</span>
<span>  compute_options <span class="op">=</span> </span>
<span>    <span class="fu"><a href="../reference/set_compute_options.html">set_compute_options</a></span><span class="op">(</span>nmc <span class="op">=</span> <span class="fl">11000</span>, burnin <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>                        rho_thinning <span class="op">=</span> <span class="fl">10</span>, include_wcd <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>,</span>
<span>  cl <span class="op">=</span> <span class="va">cl</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/parallel/makeCluster.html" class="external-link">stopCluster</a></span><span class="op">(</span><span class="va">cl</span><span class="op">)</span></span></code></pre></div>
<p>We then create an elbow plot:</p>
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/plot_elbow.html">plot_elbow</a></span><span class="op">(</span><span class="va">bmm</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="cluster_elbow-1.png" alt="Elbow plot for deciding on the number of mixture components."><div class="figcaption">Elbow plot for deciding on the number of mixture
components.</div>
</div>
<p>Although not clear-cut, we see that the within-cluster sum of
distances levels off at around 5 clusters, and hence we choose to use 5
clusters in our model.</p>
</div>
<div class="section level3">
<h3 id="posterior-distributions-1">Posterior distributions<a class="anchor" aria-label="anchor" href="#posterior-distributions-1"></a>
</h3>
<p>Having chosen 5 mixture components, we go on to fit a final model,
still running 10,000 iterations after burnin. This time we call
<code>compute_mallows</code> and set <code>n_clusters = 5</code>. We
also set <code>clus_thinning = 10</code> to save the cluster assignments
of each assessor in every 10th iteration, and
<code>rho_thinning = 10</code> to save the estimated latent rank every
10th iteration. Note that thinning is done only for because saving the
values at every iteration would result in very large objects being
stored in memory, thus slowing down computation. For statistical
efficiency, it is best to avoid thinning.</p>
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">bmm</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_mallows.html">compute_mallows</a></span><span class="op">(</span></span>
<span>  data <span class="op">=</span> <span class="va">sushi_data</span>,</span>
<span>  model_options <span class="op">=</span> <span class="fu"><a href="../reference/set_model_options.html">set_model_options</a></span><span class="op">(</span>n_cluster <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>,</span>
<span>  compute_options <span class="op">=</span> <span class="fu"><a href="../reference/set_compute_options.html">set_compute_options</a></span><span class="op">(</span></span>
<span>    nmc <span class="op">=</span> <span class="fl">11000</span>, burnin <span class="op">=</span> <span class="fl">1000</span>, clus_thinning <span class="op">=</span> <span class="fl">10</span>, rho_thinning <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We can plot the posterior distributions of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>Œ±</mi><annotation encoding="application/x-tex">\alpha</annotation></semantics></math>
and
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ùõí</mi><annotation encoding="application/x-tex">\boldsymbol{\rho}</annotation></semantics></math>
in each cluster using <code>plot.BayesMallows</code> as shown previously
for the potato data.</p>
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">bmm</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="cluster_posterior_alpha-1.png" alt="Posterior of scale parameter in each cluster."><div class="figcaption">Posterior of scale parameter in each
cluster.</div>
</div>
<p>Since there are five clusters, the easiest way of visualizing
posterior rankings is by choosing a single item.</p>
<div class="sourceCode" id="cb35"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">bmm</span>, parameter <span class="op">=</span> <span class="st">"rho"</span>, items <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="cluster_posterior_rho-1.png" alt="Posterior of item 1 in each cluster."><div class="figcaption">Posterior of item 1 in each cluster.</div>
</div>
<p>We can also show the posterior distributions of the cluster
probabilities.</p>
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">bmm</span>, parameter <span class="op">=</span> <span class="st">"cluster_probs"</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="cluster_probs_posterior-1.png" alt="Posterior for cluster probabilities."><div class="figcaption">Posterior for cluster probabilities.</div>
</div>
<p>Using the argument <code>parameter = "cluster_assignment"</code>, we
can visualize the posterior probability for each assessor of belonging
to each cluster:</p>
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">bmm</span>, parameter <span class="op">=</span> <span class="st">"cluster_assignment"</span><span class="op">)</span></span></code></pre></div>
<div class="float">
<img src="cluster_assignment_posterior-1.png" alt="Posterior for cluster assignment."><div class="figcaption">Posterior for cluster assignment.</div>
</div>
<p>The number underlying the plot can be found using
<code>assign_cluster</code>.</p>
<p>We can find clusterwise consensus rankings using
<code>compute_consensus</code>.</p>
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cp_consensus</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/compute_consensus.html">compute_consensus</a></span><span class="op">(</span><span class="va">bmm</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/reshape.html" class="external-link">reshape</a></span><span class="op">(</span></span>
<span>  <span class="va">cp_consensus</span>, </span>
<span>  direction <span class="op">=</span> <span class="st">"wide"</span>, </span>
<span>  idvar <span class="op">=</span> <span class="st">"ranking"</span>,</span>
<span>  timevar <span class="op">=</span> <span class="st">"cluster"</span>,</span>
<span>  varying <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/unique.html" class="external-link">unique</a></span><span class="op">(</span><span class="va">cp_consensus</span><span class="op">$</span><span class="va">cluster</span><span class="op">)</span><span class="op">)</span>,</span>
<span>  drop <span class="op">=</span> <span class="st">"cumprob"</span></span>
<span>  <span class="op">)</span></span>
<span><span class="co">#&gt;    ranking     Cluster 1     Cluster 2     Cluster 3     Cluster 4     Cluster 5</span></span>
<span><span class="co">#&gt; 1        1        shrimp    fatty tuna    fatty tuna    sea urchin    fatty tuna</span></span>
<span><span class="co">#&gt; 2        2       sea eel          tuna    salmon roe    fatty tuna    sea urchin</span></span>
<span><span class="co">#&gt; 3        3         squid       sea eel    sea urchin    salmon roe          tuna</span></span>
<span><span class="co">#&gt; 4        4           egg        shrimp          tuna       sea eel    salmon roe</span></span>
<span><span class="co">#&gt; 5        5    fatty tuna     tuna roll        shrimp        shrimp       sea eel</span></span>
<span><span class="co">#&gt; 6        6          tuna         squid     tuna roll          tuna     tuna roll</span></span>
<span><span class="co">#&gt; 7        7     tuna roll           egg         squid         squid        shrimp</span></span>
<span><span class="co">#&gt; 8        8 cucumber roll cucumber roll       sea eel     tuna roll         squid</span></span>
<span><span class="co">#&gt; 9        9    salmon roe    salmon roe           egg           egg           egg</span></span>
<span><span class="co">#&gt; 10      10    sea urchin    sea urchin cucumber roll cucumber roll cucumber roll</span></span></code></pre></div>
<p>Note that for estimating cluster specific parameters, label switching
is a potential problem that needs to be handled.
<code>BayesMallows</code> ignores label switching issues inside the
MCMC, because it has been shown that this approach is better for
ensuring full convergence of the chain <span class="citation">(<a href="#ref-jasra2005">Jasra, Holmes, and Stephens 2005</a>; <a href="#ref-celeux2000">Celeux, Hurn, and Robert 2000</a>)</span>. MCMC
iterations can be re-ordered after convergence is achieved, for example
by using the implementation of Stephens‚Äô algorithm <span class="citation">(<a href="#ref-Stephens2000">Stephens 2000</a>)</span>
provided by the R package <code>label.switching</code> <span class="citation">(<a href="#ref-papastamoulis2016">Papastamoulis
2016</a>)</span>. A full example of how to assess label switching is
provided in the examples for the <code>compute_mallows</code>
function.</p>
</div>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-celeux2000" class="csl-entry">
Celeux, G., M. Hurn, and C. Robert. 2000. <span>‚ÄúComputational and
Inferential Difficulties with Mixture Posterior Distribution.‚Äù</span>
<em>Journal of the American Statistical Association</em> 95 (451):
957‚Äì70. <a href="https://doi.org/10.2307/2669477" class="external-link">https://doi.org/10.2307/2669477</a>.
</div>
<div id="ref-jasra2005" class="csl-entry">
Jasra, A., C. C. Holmes, and D. A. Stephens. 2005. <span>‚ÄúMarkov Chain
<span>M</span>onte <span>C</span>arlo Methods and the Label Switching
Problem in <span>B</span>ayesian Mixture Modeling.‚Äù</span>
<em>Statistical Science</em> 20 (1): 50‚Äì67.
</div>
<div id="ref-kamishima2003" class="csl-entry">
Kamishima, T. 2003. <span>‚ÄúNantonac Collaborative Filtering:
Recommendation Based on Order Responses.‚Äù</span> In <em>Proceedings of
the Ninth ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining</em>, 583‚Äì88. New York, NY, USA: ACM.
</div>
<div id="ref-liu2019" class="csl-entry">
Liu, Q., Marta Crispino, I. Scheel, V. Vitelli, and A. Frigessi. 2019.
<span>‚ÄúModel-Based Learning from Preference Data.‚Äù</span> <em>Annual
Review of Statistics and Its Application</em> 6 (1). <a href="https://doi.org/10.1146/annurev-statistics-031017-100213" class="external-link">https://doi.org/10.1146/annurev-statistics-031017-100213</a>.
</div>
<div id="ref-papastamoulis2016" class="csl-entry">
Papastamoulis, Panagiotis. 2016. <span>‚ÄúLabel.switching: An r Package
for Dealing with the Label Switching Problem in MCMC Outputs.‚Äù</span>
<em>Journal of Statistical Software, Code Snippets</em> 69 (1): 1‚Äì24. <a href="https://doi.org/10.18637/jss.v069.c01" class="external-link">https://doi.org/10.18637/jss.v069.c01</a>.
</div>
<div id="ref-sorensen2020" class="csl-entry">
S√∏rensen, √òystein, Marta Crispino, Qinghua Liu, and Valeria Vitelli.
2020. <span>‚Äú<span>BayesMallows</span>: <span>An R Package</span> for
the <span>Bayesian Mallows Model</span>.‚Äù</span> <em>The R Journal</em>
12 (1): 324‚Äì42. <a href="https://doi.org/10.32614/RJ-2020-026" class="external-link">https://doi.org/10.32614/RJ-2020-026</a>.
</div>
<div id="ref-Stephens2000" class="csl-entry">
Stephens, Matthew. 2000. <span>‚ÄúDealing with Label Switching in Mixture
Models.‚Äù</span> <em>Journal of the Royal Statistical Society: Series B
(Statistical Methodology)</em> 62 (4): 795‚Äì809. <a href="https://doi.org/10.1111/1467-9868.00265" class="external-link">https://doi.org/10.1111/1467-9868.00265</a>.
</div>
<div id="ref-vitelli2018" class="csl-entry">
Vitelli, V., √ò. S√∏rensen, M. Crispino, E. Arjas, and A. Frigessi. 2018.
<span>‚ÄúProbabilistic Preference Learning with the Mallows Rank
Model.‚Äù</span> <em>Journal of Machine Learning Research</em> 18 (1):
1‚Äì49. <a href="https://jmlr.org/papers/v18/15-481.html" class="external-link">https://jmlr.org/papers/v18/15-481.html</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Oystein Sorensen, Waldir Leoncio, Valeria Vitelli, Marta Crispino, Qinghua Liu, Cristina Mollica, Luca Tardella, Anja Stein.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.1.</p>
</div>

    </footer>
</div>





  </body>
</html>
