<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="BayesMallows">
<title>Sequential Inference with the Mallows Model • BayesMallows</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Sequential Inference with the Mallows Model">
<meta property="og:description" content="BayesMallows">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">BayesMallows</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.5.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/BayesMallows.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/SMC-Mallows.html">Sequential Inference with the Mallows Model</a>
    <a class="dropdown-item" href="../articles/parallel_chains.html">MCMC with Parallel Chains</a>
  </div>
</li>
<li class="nav-item">
  <a class="nav-link" href="../news/index.html">Changelog</a>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/ocbe-uio/BayesMallows/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Sequential Inference with the Mallows Model</h1>
                        <h4 data-toc-skip class="author">Anja Stein</h4>
            
            <h4 data-toc-skip class="date">2021-10-25</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/ocbe-uio/BayesMallows/blob/HEAD/vignettes/SMC-Mallows.Rmd" class="external-link"><code>vignettes/SMC-Mallows.Rmd</code></a></small>
      <div class="d-none name"><code>SMC-Mallows.Rmd</code></div>
    </div>

    
    
<p>This vignette describes the <code>SMC-Mallows</code> functions of the
package. These use Sequential Monte Carlo (SMC) algorithms to provide
updated approximations to the posterior distribution of a single Mallows
model. We consider scenarios where we receive sequential information in
the form of complete rankings, partial rankings and updated rankings
from existing individuals who have previously provided a (partial)
ranking. We use an alternative data augmentation method, called the
pseudolikelihood approach, when we are using the footrule and Spearman
distance functions instead of using an independent sampler.
<code>SMC-Mallow</code> uses functions similar to their base MCMC
counterparts in the <code>BayesMallows</code> package, to visualise and
analyse the posterior distributions.</p>
<p>For an in-depth treatment of the implemented methodology, see <span class="citation">Stein (<a href="#ref-steinSequentialInferenceMallows2023" role="doc-biblioref">2023</a>)</span>.</p>
<div class="section level3">
<h3 id="smc-mallows-functions">SMC-Mallows functions<a class="anchor" aria-label="anchor" href="#smc-mallows-functions"></a>
</h3>
<table class="table">
<colgroup>
<col width="40%">
<col width="60%">
</colgroup>
<thead><tr class="header">
<th align="left">Function Name</th>
<th align="left">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><code>smc_mallows_new_users</code></td>
<td align="left">Runs the SMC algorithm for case where we observe full
rankings as new observational data.</td>
</tr>
<tr class="even">
<td align="left"><code>smc_mallows_new_item_rank</code></td>
<td align="left">Runs the SMC algorithm for case where we observe
updated partial rankings as from existing users.</td>
</tr>
<tr class="odd">
<td align="left"><code>plot</code></td>
<td align="left">Plots posterior density of <span class="math inline">\(\boldsymbol{\rho}\)</span> or <span class="math inline">\(\alpha\)</span> for a selection of items.</td>
</tr>
<tr class="even">
<td align="left"><code>compute_consensus</code></td>
<td align="left">Computes the CP estimate or MAP estimate of the latent
ranks.</td>
</tr>
<tr class="odd">
<td align="left"><code>compute_posterior_intervals</code></td>
<td align="left">Computes the Bayesian posterior intervals for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\boldsymbol{\rho}\)</span>.</td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>We provide a summary on the Bayesian Mallows model and the proposed
Sequential Monte Carlo framework which updates the parameter estimates
of the posterior each time we receive new observations for a fixed
computational cost. More information on the Bayesian Mallows model can
found in <span class="citation">Vitelli et al. (<a href="#ref-vitelli2018" role="doc-biblioref">2018</a>)</span> and <span class="citation">Liu et al. (<a href="#ref-liu2019" role="doc-biblioref">2019</a>)</span>, and a vignette on the
<code>BayesMallows</code> R package can be found in <span class="citation">Sørensen et al. (<a href="#ref-sorensen2020" role="doc-biblioref">2020</a>)</span>. A general discussion on SMC can
be found in <span class="citation">Del Moral, Doucet, and Jasra (<a href="#ref-del2006sequential" role="doc-biblioref">2006</a>)</span> and
<span class="citation">Doucet and Johansen (<a href="#ref-doucet2009tutorial" role="doc-biblioref">2009</a>)</span>.</p>
<div class="section level3">
<h3 id="notation">Notation<a class="anchor" aria-label="anchor" href="#notation"></a>
</h3>
<p>We have set of <span class="math inline">\(m\)</span> distinct items,
labelled <span class="math inline">\(\mathcal{A} = \{A_1, \dots, A_m
\}\)</span>, and we are asked to rank these items in order of personal
preference with respect to some attribute. This information can be
expressed as a ranking <span class="math inline">\(\boldsymbol{R} = \{
R_1 , \dots , R_m\}\)</span>, which is a mapping <span class="math inline">\(\boldsymbol{R}:\mathcal{A} \rightarrow
\mathcal{P}_m\)</span>, where <span class="math inline">\(\mathcal{P}_m\)</span> is the space of <span class="math inline">\(m\)</span>-dimensional permutations of <span class="math inline">\(\{1, \dots, m\}\)</span>. Each <span class="math inline">\(R_i \in \{1,\dots,m\}\)</span> corresponds to the
rank of an item <span class="math inline">\(A_i\)</span>. We
fundamentally assume that the preference information we receive from a
group of individuals is transitive, i.e., each individual does not
contradict themselves when specifying their preferences. In other words,
for any three distinct items <span class="math inline">\(\{A_i,A_j,A_k\}\)</span> in a set, then if <span class="math inline">\(A_i \prec A_j\)</span> and <span class="math inline">\(A_j \prec A_k\)</span>, then it must follow that
<span class="math inline">\(A_i \prec A_k\)</span>. Sometimes, we are
unable to provide full rankings, so instead we provide a ranking for a
subset of the items in <span class="math inline">\(\mathcal{A}\)</span>.
These are referred to as partial rankings. Partial rankings can occur
either randomly or an individual can specify their top-<span class="math inline">\(k\)</span> ranked items. In this scenario, we will
need perform data augmentation in order to estimate the parameters of
the Mallows model.</p>
</div>
<div class="section level3">
<h3 id="the-bayesian-mallows-model">The Bayesian Mallows Model<a class="anchor" aria-label="anchor" href="#the-bayesian-mallows-model"></a>
</h3>
<p>The Mallows model <span class="citation">(<a href="#ref-mallows1957" role="doc-biblioref">Mallows 1957</a>)</span> is a probability
distribution for ranking data. The probability of observing a ranking
<span class="math inline">\(\boldsymbol{R}\)</span> is defined as</p>
<p><span class="math display">\[p(\boldsymbol{R}) =
p(\boldsymbol{R}|\boldsymbol{\rho},\alpha) =\frac{1}{Z_m(\alpha)} \exp
\lefts\{ -\frac{\alpha}{m} { d(\boldsymbol{R}, \boldsymbol{\rho})}
\right\},\]</span></p>
<p>where: <span class="math inline">\(\boldsymbol{\rho} \in
\mathcal{P}_m\)</span> is the consensus ranking; <span class="math inline">\(\alpha &gt; 0\)</span> is the scale parameter
which represents the variability in rankings within the group of
individuals around the consensus ranking; and <span class="math inline">\(Z_m(\alpha)\)</span> is the normalisation
constant. The distance function, <span class="math inline">\(d(\cdot,\cdot) : \mathcal{P}_m \times
\mathcal{P}_m \rightarrow [0,\infty)\)</span>, measures the
‘’closeness’’ of a ranking to the consensus ranking. The Mallows
literature discusses the use of a right-invariant distance function,
which means that the distance between two items is unaffected by
relabelling of items <span class="citation">(<a href="#ref-diaconis1988" role="doc-biblioref">Diaconis 1988</a>)</span>. The distance metrics
that the <code>BayesMallows</code> R package currently uses are:
footrule, Spearman, Cayley, Kendall and Hamming. This also means that
the normalisation constant is independent of the consensus ranking.</p>
<p><span class="citation">Vitelli et al. (<a href="#ref-vitelli2018" role="doc-biblioref">2018</a>)</span> extended the Mallows model to
incorporate a Bayesian framework for inference. A uniform prior is
elicited for the consensus ranking <span class="math inline">\(\pi(\boldsymbol{\rho}) = (m!)^{-1}
1_{\mathcal{P}_m} (\boldsymbol{\rho})\)</span> in the space of <span class="math inline">\(\mathcal{P}_m\)</span>, and an exponential prior
for <span class="math inline">\(\alpha\)</span>, with density <span class="math inline">\(\pi(\alpha|\lambda) = \lambda \exp \{ -\lambda
\alpha \} 1_{[0,\infty)}(\alpha)\)</span>. Given <span class="math inline">\(M\)</span> observed complete rankings and the
prior distributions <span class="math inline">\(\pi(\boldsymbol{\rho})\)</span> and <span class="math inline">\(\pi(\alpha)\)</span>, assuming prior independence
of these variables, we have the following posterior density, known as
the Bayesian Mallows model,</p>
<p><span class="math display">\[ \pi(\boldsymbol\rho, \alpha |
\boldsymbol{R}_1, \dots, \boldsymbol{R}_M) \propto
\frac{\pi(\boldsymbol\rho)\pi(\alpha) }{[Z(\alpha)]^M}   \exp \left\{ -
\frac{\alpha}{m} \sum_{j=1}^{M} d(\boldsymbol{R}_j,
\boldsymbol\rho   )   \right\}.\]</span></p>
<p>Any posterior estimates of interest, such as the marginal posterior
for <span class="math inline">\(\boldsymbol{\rho}\)</span>, are obtained
through the use of Metropolis-Hastings based Markov Chain Monte Carlo
(MCMC) algorithm. Full details of the algorithm can be found in <span class="citation">Vitelli et al. (<a href="#ref-vitelli2018" role="doc-biblioref">2018</a>)</span>. In each iteration of the
algorithm, a new consensus ranking <span class="math inline">\(\boldsymbol{\rho}'\)</span> is proposed to
update <span class="math inline">\(\boldsymbol{\rho}\)</span> according
to a distribution which is centered around the current rank <span class="math inline">\(\boldsymbol{\rho}\)</span>. The proposal step for
<span class="math inline">\(\boldsymbol{\rho}\)</span> is done using the
leap-and-shift proposal algorithm of <span class="citation">Vitelli et
al. (<a href="#ref-vitelli2018" role="doc-biblioref">2018</a>)</span>
and a new value <span class="math inline">\(\alpha'\)</span> is
sampled from the log-normal distribution to update the current value of
<span class="math inline">\(\alpha\)</span>.</p>
<p>Inference on the Bayesian Mallows model can sample the posterior
distribution of the unknown consensus ranking and scale parameter using
a variety of observed data including: full rankings, incomplete rankings
(e.g. top-<span class="math inline">\(k\)</span> rankings and ranks
missing at random), and implicit data such as pairwise comparisons. For
example, in the case of partial rankings, we can create augmented full
ranking <span class="math inline">\(\tilde{R}_1, \dots,
\tilde{R}_M\)</span> by using an independent sampler for each assessor
containing the set of rankings not already chosen. The MCMC algorithm
alternates between sampling a new value of <span class="math inline">\(\boldsymbol{\rho}\)</span> and <span class="math inline">\(\alpha\)</span> given the current <span class="math inline">\(\tilde{R}_1, \dots, \tilde{R}_M\)</span> and
sampling <span class="math inline">\(\tilde{R}_1, \dots,
\tilde{R}_M\)</span> given the current values of <span class="math inline">\(\boldsymbol{\rho}\)</span> and <span class="math inline">\(\alpha\)</span>. The existing methods are
discussed in <span class="citation">Vitelli et al. (<a href="#ref-vitelli2018" role="doc-biblioref">2018</a>)</span> and are
provided in the <code>BayesMallows</code> R package <span class="citation">(<a href="#ref-sorensen2020" role="doc-biblioref">Sørensen et al. 2020</a>)</span>.</p>
</div>
<div class="section level3">
<h3 id="sequential-monte-carlo">Sequential Monte Carlo<a class="anchor" aria-label="anchor" href="#sequential-monte-carlo"></a>
</h3>
<p>Sequential Monte Carlo (SMC) methods are a class of sampling
algorithms which are used to estimate a sequence of target distributions
given a stream of observations over discrete time. Each target
distribution is approximated by a collection of random samples, termed
particles, at each time step and evolve according to importance sampling
and resampling steps. The literature on SMC methods is vast and diverse,
but we are interested in using SMC as an alternative to MCMC methods
<span class="citation">(<a href="#ref-chopin2002sequential" role="doc-biblioref">Chopin 2002</a>)</span>. A nice summary of the
different variants of SMC is given in <span class="citation">Del Moral,
Doucet, and Jasra (<a href="#ref-del2006sequential" role="doc-biblioref">2006</a>)</span>.</p>
<p>In SMC, the aim is to approximate a sequence of target distributions
<span class="math inline">\(\pi_t(\boldsymbol{\theta})\)</span> with
parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> that
we wish to estimate given a set of observed data <span class="math inline">\(D_t\)</span> which has accumulated up to time
<span class="math inline">\(t\)</span>. So we can write a target
distribution <span class="math inline">\(\pi_t\)</span> as a posterior
distribution</p>
<p><span class="math display">\[\pi_t(\boldsymbol{\theta})  =
\pi_t(\boldsymbol{\theta} | D_t) \propto
\pi_0(\boldsymbol{\theta})p_t(D_t| \boldsymbol{\theta}).\]</span></p>
<p>The SMC algorithm begins by generating <span class="math inline">\(N\)</span> particles using the prior distributions
for each parameter and assigning each particle an equal weight. In each
time step <span class="math inline">\(t=1,\dots,T\)</span>, we assume
that an additional <span class="math inline">\(p\)</span> independent
observations <span class="math inline">\(y_{1:p}\)</span> become
available from the target distribution. We reweight the particles in
<span class="math inline">\(\pi(\boldsymbol{\theta}| D_{t-1})\)</span>
from time <span class="math inline">\(t-1\)</span> to <span class="math inline">\(t\)</span> such that they are weighted with
respect to <span class="math inline">\(\pi(\boldsymbol{\theta}|
D_{t})\)</span>,</p>
<p><span class="math display">\[ w^{(i)}_t =
\frac{\pi(\boldsymbol{\theta}^{(i)}_{t-1}  |
D_{t})}{\pi(\boldsymbol{\theta}^{(i)}_{t-1} | D_{t-1})} \propto
\frac{p(D_t | \boldsymbol{\theta}^{(i)}_{t-1})}{p(D_{t-1} |
\boldsymbol{\theta}^{(i)}_{t-1})} = p( y_{1:p}| D_{t-1},
\boldsymbol{\theta}_{t-1}^{(i)}   ), \ i = 1,\dots,N.\]</span></p>
<p>Next, we normalise the particle weights and resample the particles
with replacement which replicates the heavier weighted particles and
discard those with negligible weights. This results in a set of equally
weighted particles <span class="math inline">\(\{
\boldsymbol{\theta}_t^{(i)}, w_t^{(i)} = \frac{1}{N} \}_{i=1}^N\)</span>
that represent a sample of the posterior distribution. A summary of the
possible methods for resampling is given in <span class="citation">Doucet and Johansen (<a href="#ref-doucet2009tutorial" role="doc-biblioref">2009</a>)</span>.</p>
<p>In the final stage, we move the particles using an MCMC kernel within
SMC after resampling to give back the diversity of particle values <span class="citation">(<a href="#ref-berzuini2001resample" role="doc-biblioref">Berzuini and Gilks 2001</a>)</span>. This
particular methodology in SMC is often referred to as the Resample-Move
framework of <span class="citation">Berzuini and Gilks (<a href="#ref-berzuini2001resample" role="doc-biblioref">2001</a>)</span>
and <span class="citation">Berzuini and Gilks (<a href="#ref-berzuini2003particle" role="doc-biblioref">2003</a>)</span>.
We can apply MCMC kernel many times as we would like since the particles
are still moving within the stationary distribution <span class="math inline">\(\pi_t\)</span>.</p>
</div>
</div>
<div class="section level2">
<h2 id="smc-mallows-user-guide">SMC-Mallows User Guide<a class="anchor" aria-label="anchor" href="#smc-mallows-user-guide"></a>
</h2>
<p>The <code>SMC-Mallows</code> functions contain algorithms to perform
the Resample-Move SMC framework of <span class="citation">Berzuini and
Gilks (<a href="#ref-berzuini2001resample" role="doc-biblioref">2001</a>)</span> using a single Mallows model. Each
algorithm begins by drawing <span class="math inline">\(N\)</span>
particles using the priors for <span class="math inline">\(\boldsymbol{\rho}\)</span> and <span class="math inline">\(\alpha\)</span> or by using specified initial
values. Each particle is also assigned equal weight so at the start of
the SMC algorithm we have <span class="math inline">\(\{\boldsymbol{\theta}^{(i)}_0 =
(\boldsymbol{\rho}_0^{(i)}, \alpha_0^{(i)}), w^{(i)}
\}_{i=1}^{N}\)</span> as the set of particles. Next, we observe some
ranking data, <span class="math inline">\(D_t\)</span>, and we calculate
the updated weights of the particles with respect to the new
observations and their contribution to the current estimated posterior
distribution before reweighting and multinomial resampling. Finally, we
perturb the particles using the Metropolis-Hastings based MCMC kernel
and we use the proposal distributions described in <span class="citation">Vitelli et al. (<a href="#ref-vitelli2018" role="doc-biblioref">2018</a>)</span> for sampling values of <span class="math inline">\(\boldsymbol{\rho}\)</span> and <span class="math inline">\(\alpha\)</span>.</p>
<div class="section level3">
<h3 id="complete-rankings">Complete Rankings<a class="anchor" aria-label="anchor" href="#complete-rankings"></a>
</h3>
<p>For this case, we assume that we observe a collection of complete
rankings from new assessors over a sequence of discrete time steps,
<span class="math inline">\(t=1,\dots, T\)</span>, such that up to a
time <span class="math inline">\(t\)</span>, we will have observed <span class="math inline">\(|M_t|\)</span> complete rankings. The particles
are reweighted such that they are representative of the underlying
distribution of the <span class="math inline">\(|M_t|\)</span> complete
rankings. The new weights for each particle are calculated as</p>
<p><span class="math display">\[\begin{align*}
        {w}^{(i)}_t(\boldsymbol{\theta}^{(i)}_{t-1},
\boldsymbol{\theta}^{(i)}_{t})
            &amp;=  \frac{  (Z_m(\alpha^{(i)}_{t-1}))^{-|M_t|} \exp
\left\{ - \frac{\alpha^{(i)}_{t-1}}{m} \sum_{j=1}^{|M_t|}
d(\mathbf{R}^{(i)}_j, \boldsymbol{\rho}^{(i)}_{t-1}   )   \right\}    }{
(Z_m(\alpha^{(i)}_{t-1}))^{-|M_{t-1}|} \exp \left\{ -
\frac{\alpha^{(i)}_{t-1}}{m} \sum_{j=1}^{|M_t|} d(\mathbf{R}^{(i)}_j,
\boldsymbol{\rho}^{(i)}_{t-1}   )   \right\}     }  \\
            &amp;= (Z_m(\alpha^{(i)}_{t-1}))^{-(|M_t|-|M_{t-1}|)}\exp
\left\{ - \frac{\alpha^{(i)}_{t-1}}{m} \sum_{j= |M_{t-1}|+1}^{|M_t|}
d(\mathbf{R}^{(i)}_j, \boldsymbol{\rho}^{(i)}_{t-1}   )   \right\} ,
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\alpha^{(i)}_{t-1}\)</span> and
<span class="math inline">\(\boldsymbol{\rho}^{(i)}_{t-1}, \
i=1,\dots,N\)</span> are the current estimated parameter values of the
Mallows posterior before we reweight.</p>
<div class="section level4">
<h4 id="demonstration">Demonstration<a class="anchor" aria-label="anchor" href="#demonstration"></a>
</h4>
<p>We are interested in updating the parameter estimates of the Bayesian
Mallows model based on the existing ranking data and new observations.
We demonstrate the <code>SMC-Mallows</code> functions using the
<code>sushi_rankings</code> dataset <span class="citation">(<a href="#ref-kamishima2003nantonac" role="doc-biblioref">Kamishima
2003</a>)</span>, which contains 5000 rankings for 10 sushi dishes.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">sushi_rankings</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##      shrimp sea eel tuna squid sea urchin salmon roe egg fatty tuna tuna roll</span></span>
<span><span class="co">## [1,]      2       8   10     3          4          1   5          9         7</span></span>
<span><span class="co">## [2,]      1       8    6     4         10          9   3          5         7</span></span>
<span><span class="co">## [3,]      2       8    3     4          6          7  10          1         5</span></span>
<span><span class="co">## [4,]      4       7    5     6          1          2   8          3         9</span></span>
<span><span class="co">## [5,]      4      10    7     5          9          3   2          8         1</span></span>
<span><span class="co">## [6,]      4       6    2    10          7          5   1          9         8</span></span>
<span><span class="co">##      cucumber roll</span></span>
<span><span class="co">## [1,]             6</span></span>
<span><span class="co">## [2,]             2</span></span>
<span><span class="co">## [3,]             9</span></span>
<span><span class="co">## [4,]            10</span></span>
<span><span class="co">## [5,]             6</span></span>
<span><span class="co">## [6,]             3</span></span></code></pre>
<p>The function <code>smc_mallows_new_users</code> with
<code>type = "complete"</code> shows the simplest version of the SMC
algorithm in action. Many of the input variables, that the function
requires, are also used in some of the existing functions in the
<code>BayesMallows</code> R package. However, we will discuss what the
new variables refer to in the algorithm. The variable <code>R_obs</code>
in this instance is a 2D dataset with the number of columns as
<code>n_items</code> and the number of rows, <span class="math inline">\(M\)</span>, represents the number of individuals
in the dataset. We begin the algorithm with no observations and in each
artificial time step we introduce a batch number of observations, this
is controlled by the variable <code>num_new_obs</code> to control the
size of the bath, and <code>Time</code> to specify the number of updates
we will perform. There is a limit on the value for <code>Time</code>,
and this depends on the number of individuals in the dataset and the
value of <code>num_new_obs</code>. In the move stage we can apply an
MCMC kernel as many times as we would like using the variable
<code>mcmc_kernel_app</code> to specify the value.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n_items</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">ncol</a></span><span class="op">(</span><span class="va">sushi_rankings</span><span class="op">)</span></span>
<span><span class="va">metric</span> <span class="op">&lt;-</span> <span class="st">"footrule"</span></span>
<span></span>
<span><span class="va">logz_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prepare_partition_function.html">prepare_partition_function</a></span><span class="op">(</span>metric <span class="op">=</span> <span class="va">metric</span>, n_items <span class="op">=</span> <span class="va">n_items</span><span class="op">)</span></span>
<span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="va">sushi_rankings</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">100</span>, <span class="op">]</span></span>
<span><span class="va">leap_size</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">floor</a></span><span class="op">(</span><span class="va">n_items</span> <span class="op">/</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">Time</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span><span class="va">smc_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/smc_mallows_new_users.html">smc_mallows_new_users</a></span><span class="op">(</span></span>
<span>  R_obs <span class="op">=</span> <span class="va">data</span>, type <span class="op">=</span> <span class="st">"complete"</span>, n_items <span class="op">=</span> <span class="va">n_items</span>,</span>
<span>  metric <span class="op">=</span> <span class="va">metric</span>, leap_size <span class="op">=</span> <span class="va">leap_size</span>,</span>
<span>  N <span class="op">=</span> <span class="va">N</span>, Time <span class="op">=</span> <span class="va">Time</span>,</span>
<span>  logz_estimate <span class="op">=</span> <span class="va">logz_list</span><span class="op">$</span><span class="va">logz_estimate</span>,</span>
<span>  cardinalities <span class="op">=</span> <span class="va">logz_list</span><span class="op">$</span><span class="va">cardinalities</span>,</span>
<span>  mcmc_kernel_app <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  num_new_obs <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  alpha_prop_sd <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fl">0.15</span>,</span>
<span>  alpha_max <span class="op">=</span> <span class="fl">1e6</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The example <code>smc_test</code> returns a list variable of the
particles values for <span class="math inline">\(\boldsymbol{\rho}\)</span> and <span class="math inline">\(\alpha\)</span> at each time step, so we can
observe the posterior as it evolves. Specifically the list contains a
three dimensional matrix of size <code>N</code> by <code>n_items</code>
by <code>Time+1</code>, named <code>rho_samples</code>, and an
<code>N</code> by <code>Time+1</code> matrix called
<code>alpha_samples</code>. These matrices can be studied using some
post-processing functions for visualising and analysing the posterior.
It is also possible to make comparative results using the MCMC algorithm
and the SMC algorithm. Unlike MCMC we cannot observe the trace plots and
we do not need to specify a non-zero value for the burn-in. The indexing
in R means that we have to view the <code>Time+1</code> slice of the
output in order to view the posterior once all 100 rankings have been
observed.</p>
<p>Here, we can observe the posterior probabilities of <span class="math inline">\(\boldsymbol{\rho}\)</span> for a selection of
items can be observed by calling the function <code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code>.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">smc_test</span>, colnames <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">sushi_rankings</span><span class="op">)</span>, parameter <span class="op">=</span> <span class="st">"rho"</span><span class="op">)</span></span></code></pre></div>
<p><img src="SMC-Mallows_files/figure-html/smc_complete_analysis_heatplot-1.png" width="700"></p>
<p>The posterior distributions of <span class="math inline">\(\boldsymbol{\rho}\)</span> and <span class="math inline">\(\alpha\)</span> can be studied with some of the
the analysis tools provided by <code>SMC-Mallows</code>. The posterior
intervals for the consensus ranking of each sushi item are obtained by
calling <code>compute_posterior_intervals</code>.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/compute_posterior_intervals.html">compute_posterior_intervals</a></span><span class="op">(</span><span class="va">smc_test</span>, parameter <span class="op">=</span> <span class="st">"rho"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##       item parameter  mean median conf_level  hpdi central_interval</span></span>
<span><span class="co">## 1   Item 1       rho 3.601      4       95 % [2,5]    [2.000,5.000]</span></span>
<span><span class="co">## 2  Item 10       rho 9.982     10       95 %  [10]         [10.000]</span></span>
<span><span class="co">## 3   Item 2       rho 4.235      4       95 % [2,5]    [2.000,6.000]</span></span>
<span><span class="co">## 4   Item 3       rho 2.191      2       95 % [2,3]    [2.000,4.000]</span></span>
<span><span class="co">## 5   Item 4       rho 6.548      6       95 % [6,8]    [5.000,8.000]</span></span>
<span><span class="co">## 6   Item 5       rho 7.713      8       95 % [6,9]    [6.000,9.000]</span></span>
<span><span class="co">## 7   Item 6       rho 4.048      4       95 % [3,5]    [2.000,5.000]</span></span>
<span><span class="co">## 8   Item 7       rho 8.936      9       95 % [8,9]    [8.000,9.000]</span></span>
<span><span class="co">## 9   Item 8       rho 1.000      1       95 %   [1]          [1.000]</span></span>
<span><span class="co">## 10  Item 9       rho 6.746      7       95 % [6,8]    [6.000,8.000]</span></span></code></pre>
<p>We can also rank the sushi items according to their cumulative
probability (CP) consensus and their maximum posterior rankings (MAP).
These are calculated by calling the function
<code>compute_consensus_rho</code>. We demonstrate with the CP
consensus, which is the default.</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/compute_consensus.html">compute_consensus</a></span><span class="op">(</span><span class="va">smc_test</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##    ranking    item cumprob</span></span>
<span><span class="co">## 1        1  Item 8   1.000</span></span>
<span><span class="co">## 2        2  Item 3   0.872</span></span>
<span><span class="co">## 3        3  Item 1   0.451</span></span>
<span><span class="co">## 4        4  Item 6   0.601</span></span>
<span><span class="co">## 5        5  Item 2   0.955</span></span>
<span><span class="co">## 6        6  Item 4   0.553</span></span>
<span><span class="co">## 7        7  Item 9   0.937</span></span>
<span><span class="co">## 8        8  Item 5   0.919</span></span>
<span><span class="co">## 9        9  Item 7   0.983</span></span>
<span><span class="co">## 10      10 Item 10   1.000</span></span></code></pre>
<p>Similarly, we can observe the posterior density and the posterior
intervals for the scale parameter using the functions
<code><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot()</a></code> and <code>compute_posterior_intervals</code>.</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">smc_test</span>, nmc <span class="op">=</span> <span class="va">N</span>, burnin <span class="op">=</span> <span class="fl">0</span>, parameter <span class="op">=</span> <span class="st">"alpha"</span><span class="op">)</span></span></code></pre></div>
<p><img src="SMC-Mallows_files/figure-html/smc_complete_alpha_analysis-1.png" width="700"></p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/compute_posterior_intervals.html">compute_posterior_intervals</a></span><span class="op">(</span><span class="va">smc_test</span>, parameter <span class="op">=</span> <span class="st">"alpha"</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##   parameter  mean median conf_level          hpdi central_interval</span></span>
<span><span class="co">## 1     alpha 1.697  1.692       95 % [1.447,1.966]    [1.446,1.965]</span></span></code></pre>
</div>
</div>
<div class="section level3">
<h3 id="partial-rankings">Partial Rankings<a class="anchor" aria-label="anchor" href="#partial-rankings"></a>
</h3>
<div class="section level4">
<h4 id="pseudolikelihood-sampler">Pseudolikelihood Sampler<a class="anchor" aria-label="anchor" href="#pseudolikelihood-sampler"></a>
</h4>
<p>In <span class="citation">Vitelli et al. (<a href="#ref-vitelli2018" role="doc-biblioref">2018</a>)</span>, the augmentation scheme for
partially observed rankings is done by using an independent sampler
conditioned in the observed component of each ranking. The drawback of
this approach is that it does not take into account any existing
information, such as the current estimates of the consensus ranking and
the scale parameter. We have an option to use an alternative
augmentation kernel where, for each item, we use a univariate Mallows
distribution to select each rank to an item based on the item’s rank in
the estimated consensus ranking and the scale parameter. This approach
is similar to the importance sampling approximation of the normalisation
constant of the Bayesian Mallows model, full details can be found in
<span class="citation">Vitelli et al. (<a href="#ref-vitelli2018" role="doc-biblioref">2018</a>)</span>. This particular augmentation
method only applies if we are using the footrule and Spearman distance
metric.</p>
</div>
<div class="section level4">
<h4 id="new-assessors-with-partial-rankings">New Assessors with Partial Rankings<a class="anchor" aria-label="anchor" href="#new-assessors-with-partial-rankings"></a>
</h4>
<p>We augment the missing item ranks in each <span class="math inline">\(\mathbf{R}\)</span> to create a complete auxiliary
ranking <span class="math inline">\(\tilde{\mathbf{R}}\)</span> in order
to perform the remaining steps of the SMC algorithm. We reweight the
particles such that are representative of the underlying distribution of
the <span class="math inline">\(|M_t|\)</span> augmented rankings. The
particle weights are recalculated as</p>
<p><span class="math display">\[\begin{align*}
        {w}^{(i)}_t(\boldsymbol{\theta}^{(i)}_{t-1},
\boldsymbol{\theta}^{(i)}_{t})
            &amp;= (Z_m(\alpha^{(i)}_{t-1}))^{-(|M_t|-|M_{t-1}|)}\exp
\left\{ - \frac{\alpha^{(i)}_{t-1}}{m} \sum_{j= |M_{t-1}|+1}^{|M_t|}
d(\tilde{\mathbf{R}}^{(i)}_j,
\boldsymbol{\rho}^{(i)}_{t-1}   )   \right\} \\
            &amp; \times \prod_{j = |M_{t-1}|+1}^{|M_t|}
q(\tilde{\mathbf{R}}^{(i)}_j | \mathbf{R}_j,
\boldsymbol{\rho}_{t-1}^{(i)}, \alpha_{t-1}^{(i)} ),
\end{align*}\]</span></p>
<p>where <span class="math inline">\(\alpha^{(i)}_{t-1}\)</span> and
<span class="math inline">\(\boldsymbol{\rho}^{(i)}_{t-1}, \
i=1,\dots,N\)</span> are the current estimated parameter values of the
Mallows posterior before we reweight. The distribution <span class="math inline">\(q()\)</span> represents the probability of
creating an augmented ranking <span class="math inline">\(\tilde{\mathbf{R}}\)</span> given the observed
ranking <span class="math inline">\(\mathbf{R}\)</span> and the current
estimated parameters of the posterior.</p>
</div>
<div class="section level4">
<h4 id="demonstration-1">Demonstration<a class="anchor" aria-label="anchor" href="#demonstration-1"></a>
</h4>
<p>For this demonstration we shall assume that we can only observe the
top-5 ranked items from each user in the first 100 rows of the
<code>sushi_rankings</code> dataset.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data_partial</span> <span class="op">&lt;-</span> <span class="va">sushi_rankings</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">100</span>, <span class="op">]</span></span>
<span><span class="va">data_partial</span><span class="op">[</span><span class="va">data_partial</span> <span class="op">&gt;</span> <span class="fl">5</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="cn">NA</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data_partial</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##      shrimp sea eel tuna squid sea urchin salmon roe egg fatty tuna tuna roll</span></span>
<span><span class="co">## [1,]      2      NA   NA     3          4          1   5         NA        NA</span></span>
<span><span class="co">## [2,]      1      NA   NA     4         NA         NA   3          5        NA</span></span>
<span><span class="co">## [3,]      2      NA    3     4         NA         NA  NA          1         5</span></span>
<span><span class="co">## [4,]      4      NA    5    NA          1          2  NA          3        NA</span></span>
<span><span class="co">## [5,]      4      NA   NA     5         NA          3   2         NA         1</span></span>
<span><span class="co">## [6,]      4      NA    2    NA         NA          5   1         NA        NA</span></span>
<span><span class="co">##      cucumber roll</span></span>
<span><span class="co">## [1,]            NA</span></span>
<span><span class="co">## [2,]             2</span></span>
<span><span class="co">## [3,]            NA</span></span>
<span><span class="co">## [4,]            NA</span></span>
<span><span class="co">## [5,]            NA</span></span>
<span><span class="co">## [6,]             3</span></span></code></pre>
<p>We can call the function <code>smc_mallows_new_users</code> with
<code>type = "partial"</code> to run the SMC algorithm for partial
ranking data. The variable <code>aug_method</code> allows you to choose
which data augmentation method to use on the partial ranking data. The
option <code>"pseudolikelihood"</code> is only compatible with when
selecting the distance metric as either <code>"footrule"</code> or
<code>"spearman"</code>.</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">aug_method</span> <span class="op">&lt;-</span> <span class="st">"pseudolikelihood"</span></span>
<span><span class="va">metric</span> <span class="op">&lt;-</span> <span class="st">"cayley"</span></span>
<span><span class="co"># example of selecting the incorrect combination of metric and aug_method</span></span>
<span><span class="va">smc_partial_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/smc_mallows_new_users.html">smc_mallows_new_users</a></span><span class="op">(</span></span>
<span>  R_obs <span class="op">=</span> <span class="va">data_partial</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"partial"</span>,</span>
<span>  n_items <span class="op">=</span> <span class="va">n_items</span>,</span>
<span>  metric <span class="op">=</span> <span class="va">metric</span>,</span>
<span>  leap_size <span class="op">=</span> <span class="va">leap_size</span>, N <span class="op">=</span> <span class="va">N</span>,</span>
<span>  Time <span class="op">=</span> <span class="va">Time</span>,</span>
<span>  logz_estimate <span class="op">=</span> <span class="va">logz_list</span><span class="op">$</span><span class="va">logz_estimate</span>,</span>
<span>  cardinalities <span class="op">=</span> <span class="va">logz_list</span><span class="op">$</span><span class="va">cardinalities</span>,</span>
<span>  mcmc_kernel_app <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  num_new_obs <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  alpha_prop_sd <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fl">0.15</span>,</span>
<span>  alpha_max <span class="op">=</span> <span class="fl">1e6</span>,</span>
<span>  aug_method <span class="op">=</span> <span class="va">aug_method</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>This time we call the function again but this time we provide a valid
combination of the augmentation method and the distance metric.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">aug_method</span> <span class="op">&lt;-</span> <span class="st">"pseudolikelihood"</span></span>
<span><span class="va">metric</span> <span class="op">&lt;-</span> <span class="st">"footrule"</span></span>
<span><span class="va">smc_partial_test</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/smc_mallows_new_users.html">smc_mallows_new_users</a></span><span class="op">(</span></span>
<span>  R_obs <span class="op">=</span> <span class="va">data_partial</span>,</span>
<span>  type <span class="op">=</span> <span class="st">"partial"</span>,</span>
<span>  n_items <span class="op">=</span> <span class="va">n_items</span>,</span>
<span>  metric <span class="op">=</span> <span class="va">metric</span>,</span>
<span>  leap_size <span class="op">=</span> <span class="va">leap_size</span>, N <span class="op">=</span> <span class="va">N</span>,</span>
<span>  Time <span class="op">=</span> <span class="va">Time</span>,</span>
<span>  logz_estimate <span class="op">=</span> <span class="va">logz_list</span><span class="op">$</span><span class="va">logz_estimate</span>,</span>
<span>  cardinalities <span class="op">=</span> <span class="va">logz_list</span><span class="op">$</span><span class="va">cardinalities</span>,</span>
<span>  mcmc_kernel_app <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  num_new_obs <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  alpha_prop_sd <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fl">0.15</span>,</span>
<span>  alpha_max <span class="op">=</span> <span class="fl">1e6</span>,</span>
<span>  aug_method <span class="op">=</span> <span class="va">aug_method</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>The variable <code>smc_test_partial</code> contains a list with three
dimensional matrix of size <code>N</code> by <code>n_items</code> by
<code>Time+1</code>, named <code>rho_samples</code>, and a
<code>N</code> by <code>Time+1</code> matrix called
<code>alpha_samples</code>. The analysis performed in the previous
demonstration can be applied to this scenario. Here, we can observe the
posterior probabilities for a selection of items in <span class="math inline">\(\boldsymbol{\rho}\)</span> and posterior density
for <span class="math inline">\(\alpha\)</span> as part of this
demonstration, but we can use other post processing functions to analyse
the output.</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">smc_partial_test</span>, colnames <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colnames.html" class="external-link">colnames</a></span><span class="op">(</span><span class="va">sushi_rankings</span><span class="op">)</span>, parameter <span class="op">=</span> <span class="st">"rho"</span><span class="op">)</span></span></code></pre></div>
<p><img src="SMC-Mallows_files/figure-html/smc_partial_analysis-1.png" width="700"></p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">smc_partial_test</span>, nmc <span class="op">=</span> <span class="va">N</span>, burnin <span class="op">=</span> <span class="fl">0</span>, parameter <span class="op">=</span> <span class="st">"alpha"</span><span class="op">)</span></span></code></pre></div>
<p><img src="SMC-Mallows_files/figure-html/smc_partial_analysis-2.png" width="700"></p>
</div>
</div>
<div class="section level3">
<h3 id="updated-partial-rankings">Updated partial rankings<a class="anchor" aria-label="anchor" href="#updated-partial-rankings"></a>
</h3>
<p>We can view this scenario as a observing an updated partial ranking
from an known individual, but a previously latent ranking for an
unranked items becomes known. For example, an individual may provided a
partial ranking for 6 items <span class="math inline">\((1,2,3,\texttt{NA},\texttt{NA},\texttt{NA})\)</span>
and in the SMC algorithm we might have obtained an augmented ranking
<span class="math inline">\((1,2,3,5,6,4)\)</span>. However, later on
the same individual may have provided more information about their
ranking, e.g., <span class="math inline">\((1,2,3,4,\texttt{NA},\texttt{NA})\)</span>, and
this ranking is no longer consistent with the augmented ranking. This
causes a problem where we have an augmented complete ranking through
SMC, conditioned on the original observed partial ranking, that happens
to be no longer consistent with the new observed partial ranking. This
means that our algorithm has an additional step before the reweighting
stage. In order to reweight the particles correctly as a representative
sample of the current posterior, we view the new information arriving
into the system as an existing individual (and their augmented ranking)
leaving the system completely and then re-entering as a new partial
ranking with its extra information. For each individual leaving and
re-entering the system, we have to make two weight adjustments to
account for these actions.</p>
<div class="section level4">
<h4 id="demonstration-2">Demonstration<a class="anchor" aria-label="anchor" href="#demonstration-2"></a>
</h4>
<p>To illustrate how to perform SMC for updated partial rankings, we
will modify a much smaller dataset called <code>potato_visual</code>.
This dataset, which is described in <span class="citation">Liu et al.
(<a href="#ref-liu2019" role="doc-biblioref">2019</a>)</span> and is
provided in the <code>BayesMallows</code> R package, represents the
rankings given by 12 assessors on 20 potatoes based on how heavy each
potato appeared to be given their visual appearance. We create several
partial subsets of the complete dataset by removing the lowest ranked
item from each assessor from each previous subset, so that we achieve
several partial datasets which view the top 10, top 11,… top 19 highest
ranked items as well as the complete set of rankings.</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">example_dataset</span> <span class="op">&lt;-</span> <span class="va">potato_visual</span></span>
<span><span class="va">n_users</span> <span class="op">&lt;-</span> <span class="fl">12</span></span>
<span><span class="va">n_items</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span><span class="va">test_dataset</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/array.html" class="external-link">array</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">n_users</span>, <span class="va">n_items</span>, <span class="op">(</span><span class="va">n_items</span> <span class="op">/</span> <span class="fl">2</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">test_dataset</span><span class="op">[</span>, , <span class="op">(</span><span class="va">n_items</span> <span class="op">/</span> <span class="fl">2</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">potato_visual</span></span>
<span><span class="va">tt</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">ii</span> <span class="kw">in</span> <span class="op">(</span><span class="va">n_items</span> <span class="op">-</span> <span class="fl">1</span><span class="op">)</span><span class="op">:</span><span class="op">(</span><span class="va">n_items</span> <span class="op">/</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">tt</span> <span class="op">&lt;-</span> <span class="va">tt</span> <span class="op">+</span> <span class="fl">1</span></span>
<span></span>
<span>  <span class="co"># set n_users line with one more NA</span></span>
<span>  <span class="va">example_dataset</span><span class="op">[</span><span class="va">example_dataset</span> <span class="op">&gt;</span> <span class="va">ii</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="cn">NA</span></span>
<span></span>
<span>  <span class="co"># set as new time stamp</span></span>
<span>  <span class="va">test_dataset</span><span class="op">[</span>, , <span class="op">(</span><span class="op">(</span><span class="va">n_items</span> <span class="op">/</span> <span class="fl">2</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span> <span class="op">-</span> <span class="va">tt</span><span class="op">)</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="va">example_dataset</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>This means that we now have a 3D array containing 10 partial datasets
and the one complete dataset. The third dimension of the array
represents artificial time. We can view the updated partial rankings
scenario as viewing several 2D slices of the observed dataset
sequentially. So you can see, for example, that at the 5th time point,
we observe the top-14 items from <code>potato_visual</code>.</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">test_dataset</span><span class="op">[</span>, , <span class="fl">5</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]</span></span>
<span><span class="co">##  [1,]   10   NA   NA   NA    6   NA    4   NA    3     5    12     1     2</span></span>
<span><span class="co">##  [2,]   10   NA   NA   NA   11   NA    6   NA    4     3    13     1     2</span></span>
<span><span class="co">##  [3,]   12   NA   NA   NA   13   11    7   NA    6     3     8     2     1</span></span>
<span><span class="co">##  [4,]    9   NA   NA   NA   10   NA    5   NA    3     4     8     1     2</span></span>
<span><span class="co">##  [5,]   12   NA   NA   NA    7   NA    2   NA    3     9    13     1     4</span></span>
<span><span class="co">##  [6,]   10   NA   NA   NA    8   NA    6   NA    3     7    11     1     2</span></span>
<span><span class="co">##  [7,]    9   NA   NA   NA   10   NA    5   NA    3     8    11     1     2</span></span>
<span><span class="co">##  [8,]   14   NA   NA   NA   11   NA    6   NA    4     3    10     1     2</span></span>
<span><span class="co">##  [9,]    8   NA   NA   NA   12   13    6   NA    5     3     7     1     4</span></span>
<span><span class="co">## [10,]    7   NA   NA   NA    9   NA    5   NA    3    10    11     1     2</span></span>
<span><span class="co">## [11,]   12   NA   NA   NA   13   NA    7   NA    3     5    11     1     2</span></span>
<span><span class="co">## [12,]   14   NA   NA   NA   12   NA    8   NA    3     4     9     1     2</span></span>
<span><span class="co">##       [,14] [,15] [,16] [,17] [,18] [,19] [,20]</span></span>
<span><span class="co">##  [1,]     9    NA     8     7    14    13    11</span></span>
<span><span class="co">##  [2,]     7    NA     8     5    12     9    14</span></span>
<span><span class="co">##  [3,]     4    NA     5     9    14    10    NA</span></span>
<span><span class="co">##  [4,]     7    NA    11     6    13    14    12</span></span>
<span><span class="co">##  [5,]     5    NA    11     6     8    10    14</span></span>
<span><span class="co">##  [6,]     4    NA     9     5    13    12    14</span></span>
<span><span class="co">##  [7,]     6    NA     7     4    14    12    13</span></span>
<span><span class="co">##  [8,]     7    NA     8     5    12     9    13</span></span>
<span><span class="co">##  [9,]     2    NA    10     9    NA    14    11</span></span>
<span><span class="co">## [10,]     6    NA     8     4    13    12    14</span></span>
<span><span class="co">## [11,]     6    NA    10     4    14     8     9</span></span>
<span><span class="co">## [12,]     7    NA     6     5    13    10    11</span></span></code></pre>
<p>We can now run an experiment with the altered
<code>potato_visual</code> dataset by calling the function
<code>smc_mallows_new_item_rank</code>.</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">logz_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/prepare_partition_function.html">prepare_partition_function</a></span><span class="op">(</span>metric <span class="op">=</span> <span class="va">metric</span>, n_items <span class="op">=</span> <span class="va">n_items</span><span class="op">)</span></span>
<span></span>
<span><span class="va">Time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/dim.html" class="external-link">dim</a></span><span class="op">(</span><span class="va">test_dataset</span><span class="op">)</span><span class="op">[</span><span class="fl">3</span><span class="op">]</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">aug_method</span> <span class="op">&lt;-</span> <span class="st">"pseudolikelihood"</span></span>
<span><span class="va">metric</span> <span class="op">&lt;-</span> <span class="st">"footrule"</span></span>
<span><span class="va">smc_test_updated_partial</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/smc_mallows_new_item_rank.html">smc_mallows_new_item_rank</a></span><span class="op">(</span></span>
<span>  n_items <span class="op">=</span> <span class="va">n_items</span>,</span>
<span>  R_obs <span class="op">=</span> <span class="va">test_dataset</span>,</span>
<span>  metric <span class="op">=</span> <span class="va">metric</span>,</span>
<span>  leap_size <span class="op">=</span> <span class="va">leap_size</span>, N <span class="op">=</span> <span class="va">N</span>,</span>
<span>  Time <span class="op">=</span> <span class="va">Time</span>,</span>
<span>  logz_estimate <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  cardinalities <span class="op">=</span> <span class="va">logz_list</span><span class="op">$</span><span class="va">cardinalities</span>,</span>
<span>  mcmc_kernel_app <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  alpha_prop_sd <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fl">0.15</span>,</span>
<span>  alpha_max <span class="op">=</span> <span class="fl">1e6</span>,</span>
<span>  aug_method <span class="op">=</span> <span class="va">aug_method</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Unlike the two previous demonstrations, the final slice of the output
occurs at <code>Time</code> instead of <code>Time+1</code>. This is
because we initialised the algorithm with the first slice of the
<code>test_dataset</code> rather than initialising with no observed
data. We observe the posterior probabilities for items in <span class="math inline">\(\boldsymbol{\rho}\)</span> and posterior density
for <span class="math inline">\(\alpha\)</span> by using the same
post-processing functions as before.</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">smc_test_updated_partial</span>, parameter <span class="op">=</span> <span class="st">"rho"</span>, items <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">6</span>, <span class="fl">7</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="SMC-Mallows_files/figure-html/smc_updated_partial_analysis-1.png" width="700"></p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">smc_test_updated_partial</span>, parameter <span class="op">=</span> <span class="st">"alpha"</span><span class="op">)</span></span></code></pre></div>
<p><img src="SMC-Mallows_files/figure-html/smc_updated_partial_analysis-2.png" width="700"></p>
</div>
</div>
</div>
<div class="section level2 unnumbered">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-berzuini2001resample" class="csl-entry">
Berzuini, Carlo, and Walter Gilks. 2001. <span>“RESAMPLE-MOVE Filtering
with Cross-Model Jumps.”</span> In <em>Sequential Monte Carlo Methods in
Practice</em>, 117–38. Springer.
</div>
<div id="ref-berzuini2003particle" class="csl-entry">
Berzuini, Carlo, and Walters R Gilks. 2003. <span>“Particle Filtering
Methods for Dynamic and Static Bayesian Problems.”</span> <em>OXFORD
STATISTICAL SCIENCE SERIES</em> 1 (27): 207–27.
</div>
<div id="ref-chopin2002sequential" class="csl-entry">
Chopin, Nicolas. 2002. <span>“A Sequential Particle Filter Method for
Static Models.”</span> <em>Biometrika</em> 89 (3): 539–52.
</div>
<div id="ref-del2006sequential" class="csl-entry">
Del Moral, Pierre, Arnaud Doucet, and Ajay Jasra. 2006.
<span>“Sequential Monte Carlo Samplers.”</span> <em>Journal of the Royal
Statistical Society: Series B (Statistical Methodology)</em> 68 (3):
411–36.
</div>
<div id="ref-diaconis1988" class="csl-entry">
Diaconis, Persi. 1988. <span>“Group Representations in Probability and
Statistics.”</span> <em>Lecture Notes-Monograph Series</em> 11: i–192.
</div>
<div id="ref-doucet2009tutorial" class="csl-entry">
Doucet, Arnaud, and Adam M Johansen. 2009. <span>“A Tutorial on Particle
Filtering and Smoothing: Fifteen Years Later.”</span> <em>Handbook of
Nonlinear Filtering</em> 12 (656-704): 3.
</div>
<div id="ref-kamishima2003nantonac" class="csl-entry">
Kamishima, Toshihiro. 2003. <span>“Nantonac Collaborative Filtering:
Recommendation Based on Order Responses.”</span> In <em>Proceedings of
the Ninth ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining</em>, 583–88.
</div>
<div id="ref-liu2019" class="csl-entry">
Liu, Q., Marta Crispino, I. Scheel, V. Vitelli, and A. Frigessi. 2019.
<span>“Model-Based Learning from Preference Data.”</span> <em>Annual
Review of Statistics and Its Application</em> 6 (1). <a href="https://doi.org/10.1146/annurev-statistics-031017-100213" class="external-link">https://doi.org/10.1146/annurev-statistics-031017-100213</a>.
</div>
<div id="ref-mallows1957" class="csl-entry">
Mallows, C. L. 1957. <span>“Non-Null Ranking Models.
<span>I</span>.”</span> <em>Biometrika</em> 44 (1/2): 114–30.
</div>
<div id="ref-sorensen2020" class="csl-entry">
Sørensen, Øystein, Marta Crispino, Qinghua Liu, and Valeria Vitelli.
2020. <span>“<span>BayesMallows</span>: <span>An R Package</span> for
the <span>Bayesian Mallows Model</span>.”</span> <em>The R Journal</em>
12 (1): 324–42. <a href="https://doi.org/10.32614/RJ-2020-026" class="external-link">https://doi.org/10.32614/RJ-2020-026</a>.
</div>
<div id="ref-steinSequentialInferenceMallows2023" class="csl-entry">
Stein, Anja. 2023. <span>“Sequential <span>Inference</span> with the
<span>Mallows Model</span>.”</span> PhD thesis, Lancaster University.
</div>
<div id="ref-vitelli2018" class="csl-entry">
Vitelli, V., Ø. Sørensen, M. Crispino, E. Arjas, and A. Frigessi. 2018.
<span>“Probabilistic Preference Learning with the Mallows Rank
Model.”</span> <em>Journal of Machine Learning Research</em> 18 (1):
1–49. <a href="https://jmlr.org/papers/v18/15-481.html" class="external-link">https://jmlr.org/papers/v18/15-481.html</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Oystein Sorensen, Valeria Vitelli, Marta Crispino, Qinghua Liu, Cristina Mollica, Luca Tardella, Anja Stein.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
