% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute_mallows.R
\name{compute_mallows}
\alias{compute_mallows}
\title{Preference Learning with the Mallows Rank Model}
\usage{
compute_mallows(
  data,
  model = set_model_options(),
  compute_options = set_compute_options(),
  priors = set_priors(),
  initial_values = set_initial_values(),
  logz_estimate = NULL,
  verbose = FALSE,
  seed = NULL,
  cl = NULL
)
}
\arguments{
\item{data}{An object of class \code{"BayesMallowsData"} returned from
\code{\link[=setup_rank_data]{setup_rank_data()}}.}

\item{model}{An object of class \code{"BayesMallowsModelOptions"} returned
from \code{\link[=set_model_options]{set_model_options()}}.}

\item{compute_options}{An object of class \code{"BayesMallowsComputeOptions"}
returned from \code{\link[=set_compute_options]{set_compute_options()}}.}

\item{priors}{An object of class \code{"BayesMallowsPriors"} returned from
\code{\link[=set_priors]{set_priors()}}.}

\item{initial_values}{An object of class \code{"BayesMallowsInitialValues"} returned
from \code{\link[=set_initial_values]{set_initial_values()}}.}

\item{logz_estimate}{Estimate of the partition function, computed with
\code{\link[=estimate_partition_function]{estimate_partition_function()}}. Defaults to \code{NULL}, which
means means that \code{compute_mallows} attempts to compute the
partition function by using either a pre-defined integer sequence or a
pre-computed importance sampling estimate. When Cayley, Hamming, or
Kendall distance is used, the partition function is efficiently
computed analytically, and hence in these cases the argument is not needed,
although it will still be used if provided.}

\item{verbose}{Logical specifying whether to print out the progress of the
Metropolis-Hastings algorithm. If \code{TRUE}, a notification is printed
every 1000th iteration. Defaults to \code{FALSE}.}

\item{seed}{Optional integer to be used as random number seed.}

\item{cl}{Optional cluster returned from \code{\link[parallel:makeCluster]{parallel::makeCluster()}}. If
provided, chains will be run in parallel, one on each node of \code{cl}.}
}
\value{
A list of class BayesMallows.
}
\description{
Compute the posterior distributions of the parameters of the
Bayesian Mallows Rank Model, given rankings or preferences stated by a set
of assessors.

The \code{BayesMallows} package uses the following parametrization of the
Mallows rank model \insertCite{mallows1957}{BayesMallows}:

\deqn{p(r|\alpha,\rho) = \frac{1}{Z_{n}(\alpha)} \exp\left\{\frac{-\alpha}{n}
  d(r,\rho)\right\}}

where \eqn{r} is a ranking, \eqn{\alpha} is a scale parameter, \eqn{\rho}
is the latent consensus ranking, \eqn{Z_{n}(\alpha)} is the partition
function (normalizing constant), and \eqn{d(r,\rho)} is a distance function
measuring the distance between \eqn{r} and \eqn{\rho}. We refer to
\insertCite{vitelli2018;textual}{BayesMallows} for further details of the Bayesian
Mallows model.

\code{compute_mallows} always returns posterior distributions of the latent
consensus ranking \eqn{\rho} and the scale parameter \eqn{\alpha}. Several
distance measures are supported, and the preferences can take the form of
complete or incomplete rankings, as well as pairwise preferences.
\code{compute_mallows} can also compute mixtures of Mallows models, for
clustering of assessors with similar preferences.
}
\examples{
# ANALYSIS OF COMPLETE RANKINGS
# The example datasets potato_visual and potato_weighing contain complete
# rankings of 20 items, by 12 assessors. We first analyse these using the Mallows
# model:
model_fit <- compute_mallows(
  data = setup_rank_data(rankings = potato_visual)
  )

# We study the trace plot of the parameters
assess_convergence(model_fit, parameter = "alpha")
assess_convergence(model_fit, parameter = "rho", items = 1:4)

# Based on these plots, we set burnin = 1000.
model_fit$burnin <- 1000
# Next, we use the generic plot function to study the posterior distributions
# of alpha and rho
plot(model_fit, parameter = "alpha")
plot(model_fit, parameter = "rho", items = 10:15)

# We can also compute the CP consensus posterior ranking
compute_consensus(model_fit, type = "CP")

# And we can compute the posterior intervals:
# First we compute the interval for alpha
compute_posterior_intervals(model_fit, parameter = "alpha")
# Then we compute the interval for all the items
compute_posterior_intervals(model_fit, parameter = "rho")

# ANALYSIS OF PAIRWISE PREFERENCES
# The example dataset beach_preferences contains pairwise
# preferences between beaches stated by 60 assessors. There
# is a total of 15 beaches in the dataset.
beach_data <- setup_rank_data(
  preferences = beach_preferences
)
# We then run the Bayesian Mallows rank model
# We save the augmented data for diagnostics purposes.
model_fit <- compute_mallows(
  data = beach_data,
  compute_options = set_compute_options(save_aug = TRUE),
  verbose = TRUE)
# We can assess the convergence of the scale parameter
assess_convergence(model_fit)
# We can assess the convergence of latent rankings. Here we
# show beaches 1-5.
assess_convergence(model_fit, parameter = "rho", items = 1:5)
# We can also look at the convergence of the augmented rankings for
# each assessor.
assess_convergence(model_fit, parameter = "Rtilde",
                   items = c(2, 4), assessors = c(1, 2))
# Notice how, for assessor 1, the lines cross each other, while
# beach 2 consistently has a higher rank value (lower preference) for
# assessor 2. We can see why by looking at the implied orderings in
# beach_tc
subset(get_transitive_closure(beach_data), assessor \%in\% c(1, 2) &
         bottom_item \%in\% c(2, 4) & top_item \%in\% c(2, 4))
# Assessor 1 has no implied ordering between beach 2 and beach 4,
# while assessor 2 has the implied ordering that beach 4 is preferred
# to beach 2. This is reflected in the trace plots.


# CLUSTERING OF ASSESSORS WITH SIMILAR PREFERENCES
\dontrun{
  # The example dataset sushi_rankings contains 5000 complete
  # rankings of 10 types of sushi
  # We start with computing a 3-cluster solution
  model_fit <- compute_mallows(
    sushi_rankings,
    model = set_model_options(n_clusters = 3),
    compute_options = set_compute_options(nmc = 10000),
    verbose = TRUE)
  # We then assess convergence of the scale parameter alpha
  assess_convergence(model_fit)
  # Next, we assess convergence of the cluster probabilities
  assess_convergence(model_fit, parameter = "cluster_probs")
  # Based on this, we set burnin = 1000
  # We now plot the posterior density of the scale parameters alpha in
  # each mixture:
  model_fit$burnin <- 1000
  plot(model_fit, parameter = "alpha")
  # We can also compute the posterior density of the cluster probabilities
  plot(model_fit, parameter = "cluster_probs")
  # We can also plot the posterior cluster assignment. In this case,
  # the assessors are sorted according to their maximum a posteriori cluster estimate.
  plot(model_fit, parameter = "cluster_assignment")
  # We can also assign each assessor to a cluster
  cluster_assignments <- assign_cluster(model_fit, soft = FALSE)
  }

# DETERMINING THE NUMBER OF CLUSTERS
\dontrun{
  # Continuing with the sushi data, we can determine the number of cluster
  # Let us look at any number of clusters from 1 to 10
  # We use the convenience function compute_mallows_mixtures
  n_clusters <- seq(from = 1, to = 10)
  models <- compute_mallows_mixtures(
    n_clusters = n_clusters, rankings = sushi_rankings,
    compute_options = set_compute_options(
      nmc = 6000, alpha_jump = 10, include_wcd = TRUE)
    )
  # models is a list in which each element is an object of class BayesMallows,
  # returned from compute_mallows
  # We can create an elbow plot
  plot_elbow(models, burnin = 1000)
  # We then select the number of cluster at a point where this plot has
  # an "elbow", e.g., at 6 clusters.
}

# SPEEDING UP COMPUTION WITH OBSERVATION FREQUENCIES With a large number of
# assessors taking on a relatively low number of unique rankings, the
# observation_frequency argument allows providing a rankings matrix with the
# unique set of rankings, and the observation_frequency vector giving the number
# of assessors with each ranking. This is illustrated here for the potato_visual
# dataset
#
# assume each row of potato_visual corresponds to between 1 and 5 assessors, as
# given by the observation_frequency vector
set.seed(1234)
observation_frequency <- sample.int(n = 5, size = nrow(potato_visual), replace = TRUE)
m <- compute_mallows(
  setup_rank_data(rankings = potato_visual, observation_frequency = observation_frequency))

\dontrun{
  # This example shows how to assess if label switching happens in BayesMallows
  # We start by creating a directory in which csv files with individual
  # cluster probabilities should be saved in each step of the MCMC algorithm
  dir.create("./test_label_switch")
  # Next, we go into this directory
  setwd("./test_label_switch/")
  # For comparison, we run compute_mallows with and without saving the cluster
  # probabilities The purpose of this is to assess the time it takes to save
  # the cluster probabilites
  system.time(m <- compute_mallows(
    setup_rank_data(rankings = sushi_rankings),
    model = set_model_options(n_clusters = 6),
    compute_options = set_compute_options(nmc = 2000, save_ind_clus = FALSE),
    verbose = TRUE))
  # With this options, compute_mallows will save cluster_probs2.csv,
  # cluster_probs3.csv, ..., cluster_probs[nmc].csv.
  system.time(m <- compute_mallows(
    setup_rank_data(rankings = sushi_rankings),
    model = set_model_options(n_clusters = 6),
    compute_options = set_compute_options(nmc = 2000, save_ind_clus = TRUE),
    verbose = TRUE))

  # Next, we check convergence of alpha
  assess_convergence(m)

  # We set the burnin to 1000
  burnin <- 1000

  # Find all files that were saved. Note that the first file saved is cluster_probs2.csv
  cluster_files <- list.files(pattern = "cluster\\\\_probs[[:digit:]]+\\\\.csv")

  # Check the size of the files that were saved.
  paste(sum(do.call(file.size, list(cluster_files))) * 1e-6, "MB")

  # Find the iteration each file corresponds to, by extracting its number
  iteration_number <- as.integer(
    gsub("(^[a-zA-Z\\\\_\\\\.]*)([0-9]+)([a-zA-Z\\\\_\\\\.]+$)", "\\\\2",
         cluster_files, perl = TRUE))
  # Remove all files before burnin
  file.remove(cluster_files[iteration_number <= burnin])
  # Update the vector of files, after the deletion
  cluster_files <- list.files(pattern = "cluster\\\\_probs[[:digit:]]+\\\\.csv")
  # Create 3d array, with dimensions (iterations, assessors, clusters)
  prob_array <- array(dim = c(length(cluster_files), m$n_assessors, m$n_clusters))
  # Read each file, adding to the right element of the array
  for(i in seq_along(cluster_files)){
    prob_array[i, , ] <- as.matrix(
      read.csv(cluster_files[[i]], header = FALSE))
  }


  # Create an integer array of latent allocations, as this is required by label.switching
  z <- subset(m$cluster_assignment, iteration > burnin)
  z$value <- as.integer(gsub("Cluster ", "", z$value))
  z <- stats::reshape(z, direction = "wide", idvar = "iteration", timevar = "assessor")
  z$iteration <- NULL
  z <- as.matrix(z)

  # Now apply Stephen's algorithm
  library(label.switching)
  ls <- label.switching("STEPHENS", z = z, K = m$n_clusters, p = prob_array)

  # Check the proportion of cluster assignments that were switched
  mean(apply(ls$permutations$STEPHENS, 1, function(x) !all.equal(x, seq(1, m$n_clusters))))

  # Remove the rest of the csv files
  file.remove(cluster_files)
  # Move up one directory
  setwd("..")
  # Remove the directory in which the csv files were saved
  file.remove("./test_label_switch/")
}
}
\references{
\insertAllCited{}
}
\seealso{
\code{\link[=compute_mallows_mixtures]{compute_mallows_mixtures()}} for a function that computes
separate Mallows models for varying numbers of clusters.

Other modeling: 
\code{\link{assess_convergence}()},
\code{\link{compute_mallows_mixtures}()},
\code{\link{set_compute_options}()},
\code{\link{set_initial_values}()},
\code{\link{set_model_options}()},
\code{\link{set_priors}()},
\code{\link{setup_rank_data}()},
\code{\link{smc_mallows_new_item_rank}()},
\code{\link{smc_mallows_new_users}()}
}
\concept{modeling}
