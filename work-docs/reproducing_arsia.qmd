---
title: "Reproducing top-k experiment from ARSIA paper"
format: pdf
---

```{r}
library(BayesMallows)
library(tidyverse)
library(patchwork)
library(furrr)
library(extraDistr)
sessionInfo()
```

## Simulations

```{r}
plan(multisession)
models <- future_map(1:10, function(i) {
  k <- rtpois(12, lambda = 7, a = 1, b = 17)
  dat <- potato_visual
  colnames(dat) <- LETTERS[seq_len(ncol(dat))]
  for(i in seq_along(k)) {
    dat[i, ][dat[i, ] > k[[i]]] <- NA
  }
  compute_mallows(
    data = setup_rank_data(rankings = dat),
    compute_options = set_compute_options(
      nmc = 5e5, burnin = 1e4, alpha_jump = 10, rho_thinning = 10, 
      aug_thinning = 10),
    priors = set_priors(lambda = .1)
  )
}, .options = furrr_options(seed = 123L))
plan("default")
```

## Trace plots

The dashed black lines shows the burn-in. This looks like it converges well in the $\alpha$.

```{r}
map(models, function(m) {
  assess_convergence(m) + 
    geom_vline(xintercept = 1e4, linetype = "dashed") +
    theme_classic() + 
    theme(legend.position = "none", axis.title.x = element_blank(),
          axis.title.y = element_blank())
}) %>% 
  wrap_plots()
```

Potato 8 is ranked as the 20th by everyone except assessor 8, who ranks it 17th. However, this does not mean that potato 8 has to be ranked last, since in each simulated dataset there are many other potatoes that may also never be ranked, depending on the $k_{j}$. Anyhow, these trace plots look reasonable to me.

```{r}
map(models, function(m) {
  assess_convergence(m, parameter = "rho", items = 8) + 
    geom_vline(xintercept = 1e4, linetype = "dashed") +
    theme_classic() + 
    ylim(0, 20) +
    theme(legend.position = "none", axis.title.x = element_blank(),
          axis.title.y = element_blank())
}) %>% 
  wrap_plots()
```


## Heat plots

I'll show the heat plots one-by-one. They all look reasonable to me. We cannot hope to exactly reproduce ARSIA, since Figure 3a in the paper shows the result of just one random simulation. Note that the color scale differs between the papers.

```{r}
for(i in seq_along(models)) {
  print(heat_plot(models[[i]]))
}
```


## Mean Squared Error

Again I cannot exactly reproduce the random number seeds etc used in the ARSIA paper, but the order of magnitude here is very close to Figure 3c.

```{r}
mse <- map_dbl(models, function(m) {
  mean((potato_true_ranking - create_ranking(match(compute_consensus(m)$item, LETTERS)))^2)
})

plot(mse, xlab = "run", ylab = "MSE", ylim = c(0, max(mse)))
```

